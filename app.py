#!/usr/bin/env python3
"""
MikroTik Manager - Secured
Pridan√° webov√° registr√°cia, zobrazenie stavu prihl√°senia a mo≈ænos≈• zmeny hesla.
"""

import os
import time
import json
import sqlite3
import threading
from datetime import datetime, timedelta, timezone
import subprocess
import re
import platform
import statistics
import secrets
import string
import csv
from contextlib import contextmanager
# PRIDAN√â: g pre glob√°lny kontext po≈æiadavky
from flask import Flask, request, jsonify, send_from_directory, render_template, redirect, url_for, session, g
from flask_socketio import SocketIO, emit
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix
import paramiko
import difflib
from ftplib import FTP
import http.client
import urllib.parse
from contextlib import contextmanager
import logging
import schedule
import heapq
import itertools
from concurrent.futures import ThreadPoolExecutor

from flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user
from werkzeug.security import generate_password_hash, check_password_hash
import pyotp
import qrcode
import base64
from io import BytesIO
from cryptography.fernet import Fernet
import base64 as b64

# --- Defin√≠cie adres√°rov pred konfigur√°ciou aplik√°cie ---
DATA_DIR = os.environ.get('DATA_DIR', '/var/lib/mikrotik-manager/data')
DB_PATH = os.path.join(DATA_DIR, 'mikrotik_manager.db')
BACKUP_DIR = os.path.join(DATA_DIR, 'backups')
BOOLEAN_SETTING_KEYS = {
    'ping_monitor_enabled', 'snmp_health_check_enabled', 'backup_schedule_enabled',
    'backup_detailed_logging', 'notify_backup_success', 'notify_backup_failure',
    'notify_device_offline', 'notify_device_online', 'notify_temp_critical',
    'notify_cpu_critical', 'notify_memory_critical', 'notify_reboot_detected',
    'notify_version_change', 'quiet_hours_enabled', 'availability_monitoring_enabled',
    'debug_terminal'
}

SETTING_LABELS = {
    'availability_monitoring_enabled': 'Povoli≈• monitorovanie dostupnosti zariaden√≠',
    'backup_delay_seconds': 'Oneskorenie medzi z√°lohami (sekundy)',
    'backup_detailed_logging': 'Detailn√© logovanie z√°lohov√©ho procesu',
    'backup_retention_count': 'Poƒçet uchov√°van√Ωch z√°loh (na zariadenie)',
    'backup_schedule_day': 'De≈à v t√Ω≈ædni',
    'backup_schedule_enabled': 'Povoli≈• automatick√© z√°lohovanie',
    'backup_schedule_time': 'ƒåas z√°lohovania (HH:MM)',
    'backup_schedule_type': 'Interval z√°lohovania',
    'cpu_critical_threshold': 'CPU (%)',
    'debug_terminal': 'Debug Terminal',
    'ftp_directory': 'FTP Adres√°r',
    'ftp_password': 'FTP Heslo',
    'ftp_port': 'FTP Port',
    'ftp_server': 'FTP Server',
    'ftp_username': 'FTP Pou≈æ√≠vateƒæ',
    'log_max_entries': 'Max zobrazen√Ωch logov v okne',
    'log_retention_days': 'Uchov√°vanie aktivity logov (dni)',
    'memory_critical_threshold': 'Pam√§≈• (%)',
    'ping_check_interval_seconds': 'Ping interval (sekundy)',
    'ping_heartbeat_interval': 'Glob√°lny ping interval (sekundy)',
    'ping_monitor_enabled': 'Ping monitoring (glob√°lny prep√≠naƒç)',
    'ping_retention_days': 'ICMP ping d√°ta (dni)',
    'ping_retries': 'Poƒçet ne√∫spe≈°n√Ωch pokusov',
    'ping_retry_interval': 'Retry interval pri v√Ωpadku (sekundy)',
    'ping_timeout': 'Timeout pre jeden ping (sekundy)',
    'pushover_app_key': 'Pushover App Key/Token',
    'pushover_user_key': 'Pushover User Key',
    'quiet_hours_enabled': 'Povoli≈• \"Quiet Hours\" (tich√Ω re≈æim)',
    'quiet_hours_end': 'Tich√Ω re≈æim do',
    'quiet_hours_start': 'Tich√Ω re≈æim od',
    'snmp_check_interval_minutes': 'Glob√°lny interval SNMP zberu d√°t (min√∫ty)',
    'snmp_health_check_enabled': 'Automatick√Ω SNMP health check',
    'snmp_health_check_interval_minutes': 'Frekvencia health checku (min√∫ty)',
    'snmp_retention_days': 'SNMP v√Ωkonnostn√© d√°ta (dni)',
    'temp_critical_threshold': 'Teplota (¬∞C)',
    'notify_device_offline': 'Notifik√°cia: zariadenie offline (ICMP)',
    'notify_device_online': 'Notifik√°cia: zariadenie online (ICMP)',
    'notify_backup_success': 'Notifik√°cia: √∫spe≈°n√° z√°loha',
    'notify_backup_failure': 'Notifik√°cia: ne√∫spe≈°n√° z√°loha',
    'notify_temp_critical': 'Notifik√°cia: kritick√° teplota (SNMP)',
    'notify_cpu_critical': 'Notifik√°cia: kritick√° z√°≈•a≈æ CPU (SNMP)',
    'notify_memory_critical': 'Notifik√°cia: kritick√° pam√§≈• (SNMP)',
    'notify_reboot_detected': 'Notifik√°cia: detekovan√Ω re≈°tart',
    'notify_version_change': 'Notifik√°cia: zmena verzie OS',
    'viewport': 'Re≈æim zobrazenia'
}

SENSITIVE_SETTINGS = {'ftp_password', 'pushover_app_key', 'pushover_user_key'}

SETTING_VALUE_SUFFIXES = {
    'ping_check_interval_seconds': ' s',
    'ping_retry_interval': ' s',
    'ping_timeout': ' s',
    'ping_heartbeat_interval': ' s',
    'ping_retention_days': ' dn√≠',
    'ping_retries': ' pokusov',
    'backup_delay_seconds': ' s',
    'backup_retention_count': ' ks',
    'snmp_check_interval_minutes': ' min',
    'snmp_health_check_interval_minutes': ' min',
    'snmp_retention_days': ' dn√≠',
    'log_retention_days': ' dn√≠',
    'log_max_entries': ' z√°znamov',
    'cpu_critical_threshold': ' %',
    'memory_critical_threshold': ' %',
    'temp_critical_threshold': ' ¬∞C'
}

SCHEDULE_TYPE_LABELS = {
    'daily': 'denne',
    'weekly': 't√Ω≈ædenne',
    'monthly': 'mesaƒçne',
    'custom': 'vlastn√Ω pl√°n'
}

SCHEDULE_DAY_LABELS = {
    'monday': 'pondelok',
    'tuesday': 'utorok',
    'wednesday': 'streda',
    'thursday': '≈°tvrtok',
    'friday': 'piatok',
    'saturday': 'sobota',
    'sunday': 'nedeƒæa'
}

VIEWPORT_LABELS = {
    'desktop': 'Desktop re≈æim',
    'mobile': 'Mobiln√Ω re≈æim',
    'auto': 'Automaticky'
}

def get_setting_label(key):
    """Vr√°ti ƒçitateƒæn√Ω n√°zov nastavenia"""
    return SETTING_LABELS.get(key, key.replace('_', ' ').capitalize())

def format_setting_value(key, value):
    """Form√°tovanie hodnoty nastavenia pre logy"""
    if value is None or value == '':
        return 'nenastaven√©'
    value_str = str(value)
    lower_value = value_str.lower()
    bool_like = key in BOOLEAN_SETTING_KEYS or key.startswith('notify_') or key.endswith('_enabled')
    if bool_like:
        return 'zapnut√©' if lower_value == 'true' else 'vypnut√©'
    if key == 'backup_schedule_type':
        return SCHEDULE_TYPE_LABELS.get(lower_value, value_str)
    if key == 'backup_schedule_day':
        return SCHEDULE_DAY_LABELS.get(lower_value, value_str)
    if key == 'viewport':
        return VIEWPORT_LABELS.get(lower_value, value_str)
    suffix = SETTING_VALUE_SUFFIXES.get(key)
    if suffix:
        return f"{value_str}{suffix}"
    return value_str
DEFAULT_SETTING_VALUES = {
    'ping_check_interval_seconds': '120',
    'ping_monitor_enabled': 'true',
    'snmp_check_interval_minutes': '10',
    'snmp_health_check_enabled': 'true',
    'snmp_health_check_interval_minutes': '15',
    'backup_schedule_enabled': 'false',
    'backup_schedule_type': 'daily',
    'backup_schedule_day': 'sunday',
    'backup_schedule_time': '02:00',
    'backup_retention_count': '10',
    'backup_delay_seconds': '30',
    'backup_detailed_logging': 'false',
    'ftp_port': '21'
}

# --- Nastavenie aplik√°cie (upraven√© pre HTML ≈°abl√≥ny) ---
app = Flask(__name__, static_folder='.', static_url_path='', template_folder='.')

# PERSISTENT SECRET KEY - Bezpeƒçnostne optimalizovan√©
def get_or_create_secret_key():
    """
    Z√≠ska alebo vytvor√≠ persistent SECRET_KEY pre aplik√°ciu.
    Kƒæ√∫ƒç sa uklad√° do s√∫boru a je konzistentn√Ω medzi re≈°tartami slu≈æby.
    """
    secret_key_file = os.path.join(DATA_DIR, 'secret.key')
    
    # Ensure DATA_DIR exists for secret key
    os.makedirs(DATA_DIR, exist_ok=True)
    
    if os.path.exists(secret_key_file):
        try:
            with open(secret_key_file, 'rb') as f:
                secret_key = f.read()
                if len(secret_key) == 32:  # Platn√Ω kƒæ√∫ƒç
                    return secret_key
        except Exception as e:
            print(f"Chyba pri ƒç√≠tan√≠ SECRET_KEY s√∫boru: {e}")
    
    # Vytvor nov√Ω SECRET_KEY
    secret_key = os.urandom(32)
    try:
        with open(secret_key_file, 'wb') as f:
            f.write(secret_key)
        # Nastavenie spr√°vnych pr√°v na s√∫bor (600 - read/write owner only)
        os.chmod(secret_key_file, 0o600)
        print("Vytvoren√Ω nov√Ω persistent SECRET_KEY")
        return secret_key
    except Exception as e:
        print(f"Chyba pri ukladan√≠ SECRET_KEY: {e}")
        # Fallback na session-only kƒæ√∫ƒç
        return os.urandom(32)

app.config['SECRET_KEY'] = get_or_create_secret_key()
# PRAKTICK√â NASTAVENIE: 1 rok platnos≈• cookie (s persistent SECRET_KEY je to bezpeƒçn√©)
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=365)

# Pridanie ProxyFix pre spr√°vne spracovanie proxy hlaviƒçiek (Nginx Proxy Manager)
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)

socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')
CORS(app)

# Middleware pre povolenie iframe naƒç√≠tania
@app.after_request
def add_iframe_headers(response):
    """Prid√° hlaviƒçky pre povolenie iframe naƒç√≠tania z mobiln√Ωch aplik√°ci√≠"""
    # Povoli≈• naƒç√≠tanie v iframe (odstr√°ni X-Frame-Options)
    if 'X-Frame-Options' in response.headers:
        del response.headers['X-Frame-Options']
    
    # Prida≈• permiss√≠vny Content Security Policy pre iframe
    response.headers['Content-Security-Policy'] = (
        "default-src 'self' 'unsafe-inline' 'unsafe-eval'; "
        "frame-ancestors *; "
        "img-src 'self' data: https:; "
        "style-src 'self' 'unsafe-inline' https:; "
        "script-src 'self' 'unsafe-inline' 'unsafe-eval' https:; "
        "font-src 'self' data: https:; "
        "connect-src 'self' ws: wss: https: http:;"
    )
    
    # Prida≈• CORS hlaviƒçky pre mobiln√© aplik√°cie
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, X-Requested-With, X-Forwarded-For, X-Forwarded-Proto'
    response.headers['Access-Control-Allow-Credentials'] = 'true'
    
    # Prida≈• hlaviƒçky pre Android WebView optimaliz√°ciu
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    # Hlaviƒçky pre spr√°vne fungovanie za proxy
    if request.headers.get('X-Forwarded-Proto'):
        response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'
    
    return response

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

backup_tasks = {}
sequential_backup_running = False
# Tracking for sequential backup progress so frontend can show e.g. 1/16
sequential_backup_total = 0
sequential_backup_current = 0

# --- Password Encryption ---
def get_encryption_key():
    """Get or create encryption key for password encryption"""
    key_file = os.path.join(DATA_DIR, 'encryption.key')
    
    if os.path.exists(key_file):
        with open(key_file, 'rb') as f:
            return f.read()
    else:
        # Generate new key and save it
        key = Fernet.generate_key()
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(key_file, 'wb') as f:
            f.write(key)
        # Set secure permissions
        os.chmod(key_file, 0o600)
        return key

# Initialize encryption
ENCRYPTION_KEY = get_encryption_key()
cipher = Fernet(ENCRYPTION_KEY)

def encrypt_password(password):
    """Encrypt password for secure storage"""
    if password is None:
        return None
    return b64.b64encode(cipher.encrypt(password.encode())).decode()

def decrypt_password(encrypted_password):
    """Decrypt password for use"""
    if encrypted_password is None:
        return None
    try:
        return cipher.decrypt(b64.b64decode(encrypted_password.encode())).decode()
    except:
        # If decryption fails, assume it's already plaintext (for backward compatibility)
        return encrypted_password

def migrate_existing_passwords():
    """Migrate existing plaintext passwords to encrypted format - run once on startup"""
    try:
        with get_db_connection() as conn:
            # Get all devices
            devices = conn.execute('SELECT id, password FROM devices').fetchall()
            migrated_count = 0
            
            for device in devices:
                device_id, password = device
                if password:
                    # Check if password is already encrypted by looking at its format
                    # Encrypted passwords are base64 encoded and start with specific pattern
                    if password.startswith('Z0FBQUFBQm') or len(password) > 50:
                        # Already encrypted, skip
                        continue
                    else:
                        # Plaintext password - encrypt it
                        encrypted_password = encrypt_password(password)
                        conn.execute('UPDATE devices SET password = ? WHERE id = ?', (encrypted_password, device_id))
                        migrated_count += 1
                        logger.info(f"Migrated password for device ID {device_id}")
            
            if migrated_count > 0:
                conn.commit()
                logger.info(f"Password migration completed: {migrated_count} passwords encrypted")
            else:
                logger.info("Password migration: No plaintext passwords found")
    except Exception as e:
        logger.error(f"Password migration failed: {e}")
        import traceback
        logger.error(f"Migration error traceback: {traceback.format_exc()}")

# Helper functions for device password handling
def get_device_with_decrypted_password(device_dict):
    """Take device dict and decrypt its password"""
    if isinstance(device_dict, dict) and 'password' in device_dict:
        device_dict = device_dict.copy()  # Don't modify original
        device_dict['password'] = decrypt_password(device_dict['password'])
    return device_dict

def prepare_devices_with_decrypted_passwords(devices):
    """Decrypt passwords for a list of devices"""
    return [get_device_with_decrypted_password(dict(device)) for device in devices]

# SNMP refresh all tracking
snmp_refresh_tasks = {}
sequential_snmp_refresh_running = False
snmp_refresh_progress = {'current': 0, 'total': 0}

login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login'
login_manager.session_protection = "strong"

class User(UserMixin):
    def __init__(self, id, username, password, totp_secret, totp_enabled):
        self.id = id
        self.username = username
        self.password = password
        self.totp_secret = totp_secret
        self.totp_enabled = totp_enabled

@login_manager.user_loader
def load_user(user_id):
    with get_db_connection() as conn:
        user_data = conn.execute('SELECT * FROM users WHERE id = ?', (user_id,)).fetchone()
        if user_data:
            return User(id=user_data['id'], username=user_data['username'], password=user_data['password'], totp_secret=user_data['totp_secret'], totp_enabled=user_data['totp_enabled'])
    return None

def init_environment():
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(BACKUP_DIR, exist_ok=True)
    logger.info("Adres√°re pre d√°ta a backupy s√∫ pripraven√©.")

@contextmanager
def get_db_connection():
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        yield conn
    except sqlite3.Error as e:
        logger.error(f"Chyba pripojenia k datab√°ze: {e}")
        if conn:
            conn.rollback()
        raise
    finally:
        if conn:
            conn.close()

# Debug control helper functions (moved here to avoid NameError)
def is_debug_enabled(debug_type):
    """Kontroluje ƒçi je debug m√≥d zapnut√Ω pre dan√Ω typ"""
    try:
        with get_db_connection() as conn:
            result = conn.execute('SELECT value FROM settings WHERE key = ?', (debug_type,)).fetchone()
            return result and result[0] == 'true'
    except:
        return False

def debug_log(debug_type, message):
    """Debug log iba ak je zapnut√Ω debug m√≥d"""
    if is_debug_enabled('debug_terminal'):
        logger.debug(f"[{debug_type.upper()}] {message}")

def debug_emit(event, data):
    """Wrapper pre socketio.emit s debug logovan√≠m"""
    if is_debug_enabled('debug_terminal'):
        debug_log('debug_websocket', f"Emitting '{event}' with data: {str(data)[:200]}...")
    socketio.emit(event, data)

# Debug helper functions


# Spustenie ping monitoring threadu - glob√°lne premenn√©
ping_thread = None
ping_thread_stop_flag = threading.Event()

def start_ping_monitoring():
    """Spust√≠ ping monitoring v background thread"""
    global ping_thread
    if ping_thread is None or not ping_thread.is_alive():
        ping_thread_stop_flag.clear()
        ping_thread = threading.Thread(target=ping_monitoring_loop, daemon=True)
        ping_thread.start()
        logger.info("Ping monitoring thread spusten√Ω")

def restart_ping_monitoring():
    """Re≈°tartuje ping monitoring s nov√Ωmi nastaveniami"""
    global ping_thread, ping_thread_stop_flag
    
    # Signalizuj star√©mu threadu aby sa ukonƒçil
    ping_thread_stop_flag.set()
    
    # Poƒçkaj chv√≠ƒæu aby sa star√Ω thread ukonƒçil
    if ping_thread and ping_thread.is_alive():
        ping_thread.join(timeout=5)
    
    # Spust√≠ nov√Ω thread
    start_ping_monitoring()
    logger.info("Ping monitoring re≈°tartovan√Ω")

def init_database():
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS devices (
                id INTEGER PRIMARY KEY AUTOINCREMENT, ip TEXT UNIQUE NOT NULL, name TEXT NOT NULL,
                username TEXT NOT NULL, password TEXT NOT NULL, low_memory BOOLEAN DEFAULT 0,
                snmp_community TEXT DEFAULT 'public', status TEXT DEFAULT 'unknown',
                last_backup TIMESTAMP, last_snmp_data TEXT, snmp_interval_minutes INTEGER DEFAULT 0,
                last_snmp_check TIMESTAMP, ping_interval_seconds INTEGER DEFAULT 0,
                ping_retry_interval_seconds INTEGER DEFAULT 0, monitoring_paused BOOLEAN DEFAULT 0
            )
        ''')
        # Pridanie nov√Ωch stƒ∫pcov pre existuj√∫ce datab√°zy
        try:
            cursor.execute('ALTER TABLE devices ADD COLUMN snmp_interval_minutes INTEGER DEFAULT 0')
        except sqlite3.OperationalError:
            pass
        try:
            cursor.execute('ALTER TABLE devices ADD COLUMN last_snmp_check TIMESTAMP')
        except sqlite3.OperationalError:
            pass
        try:
            cursor.execute('ALTER TABLE devices ADD COLUMN ping_interval_seconds INTEGER DEFAULT 0')
        except sqlite3.OperationalError:
            pass
        try:
            cursor.execute('ALTER TABLE devices ADD COLUMN ping_retry_interval_seconds INTEGER DEFAULT 0')
        except sqlite3.OperationalError:
            pass
        try:
            cursor.execute('ALTER TABLE devices ADD COLUMN monitoring_paused BOOLEAN DEFAULT 0')
        except sqlite3.OperationalError:
            pass
        
        # Pridanie memory stƒ∫pcov do snmp_history tabuƒæky
        try:
            cursor.execute('ALTER TABLE snmp_history ADD COLUMN total_memory INTEGER')
        except sqlite3.OperationalError:
            pass
        try:
            cursor.execute('ALTER TABLE snmp_history ADD COLUMN free_memory INTEGER')
        except sqlite3.OperationalError:
            pass
        cursor.execute('CREATE TABLE IF NOT EXISTS settings (key TEXT PRIMARY KEY, value TEXT)')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp DATETIME NOT NULL,
                level TEXT NOT NULL, message TEXT NOT NULL, device_ip TEXT DEFAULT NULL
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                password TEXT NOT NULL,
                totp_secret TEXT,
                totp_enabled BOOLEAN NOT NULL DEFAULT 0
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS backup_codes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER NOT NULL,
                code TEXT NOT NULL,
                created_at TIMESTAMP NOT NULL,
                used BOOLEAN NOT NULL DEFAULT 0,
                used_at TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            )
        ''')
        # Pridanie tabuliek pre monitoring - ping a SNMP history
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ping_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                device_id INTEGER NOT NULL,
                timestamp DATETIME NOT NULL,
                avg_latency REAL,
                packet_loss INTEGER NOT NULL DEFAULT 0,
                status TEXT NOT NULL,
                FOREIGN KEY (device_id) REFERENCES devices (id)
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS snmp_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                device_id INTEGER NOT NULL,
                timestamp DATETIME NOT NULL,
                cpu_load INTEGER,
                temperature INTEGER,
                memory_usage INTEGER,
                uptime INTEGER,
                FOREIGN KEY (device_id) REFERENCES devices (id)
            )
        ''')
        try:
            cursor.execute('ALTER TABLE users ADD COLUMN totp_enabled BOOLEAN NOT NULL DEFAULT 0')
        except sqlite3.OperationalError:
            pass
        conn.commit()
        
        # ODSTR√ÅNEN√â: Automatick√© mazanie logov o z√°lohovani - logy si bud√∫ pam√§ta≈• aj po re≈°tarte
        
        # Pridanie predvolen√Ωch hodn√¥t pre nastavenia
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('backup_retention_count', '10'))
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('backup_delay_seconds', '30'))
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('snmp_check_interval_minutes', '10'))
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('snmp_health_check_enabled', 'true'))
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('snmp_health_check_interval_minutes', '15'))
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('backup_detailed_logging', 'false'))
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('log_retention_days', '30'))  # Pridan√©: uchov√°vanie logov
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('ping_retention_days', '30'))  # Pridan√©: uchov√°vanie ping d√°t
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('snmp_retention_days', '30'))  # Pridan√©: uchov√°vanie SNMP d√°t
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('log_max_entries', '2000'))  # Pridan√©: limit zobrazen√Ωch logov
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('notify_backup_success', 'true'))  # Notifik√°cie √∫spe≈°n√Ωch z√°loh
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('notify_backup_failure', 'true'))  # Notifik√°cie ne√∫spe≈°n√Ωch z√°loh
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('ping_check_interval_seconds', '120'))  # Ping monitoring interval v sekund√°ch
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('ping_monitor_enabled', 'true'))  # Povoli≈•/zak√°za≈• ping monitoring
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('debug_terminal', 'false'))  # Pridan√©: debug termin√°l v monitoringu
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('ping_retry_interval', '20'))  # Retry interval pri v√Ωpadku v sekund√°ch
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('ping_retries', '3'))  # Poƒçet ne√∫spe≈°n√Ωch pokusov pred oznaƒçen√≠m offline
        cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", ('ping_timeout', '5'))  # Timeout pre jeden ping
        additional_defaults = {
            'notify_device_offline': 'true',
            'notify_device_online': 'true',
            'notify_temp_critical': 'true',
            'notify_cpu_critical': 'true',
            'notify_memory_critical': 'true',
            'notify_reboot_detected': 'true',
            'notify_version_change': 'true',
            'temp_critical_threshold': '75',
            'cpu_critical_threshold': '85',
            'memory_critical_threshold': '90',
            'quiet_hours_enabled': 'false',
            'quiet_hours_start': '',
            'quiet_hours_end': ''
        }
        for key, value in additional_defaults.items():
            cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", (key, value))
        conn.commit()
        logger.info("Datab√°za √∫spe≈°ne inicializovan√°.")

@app.before_request
def before_request_handler():
    if 'user_exists' not in g:
        with get_db_connection() as conn:
            try:
                user_count = conn.execute('SELECT COUNT(id) FROM users').fetchone()[0]
                g.user_exists = user_count > 0
            except sqlite3.OperationalError:
                g.user_exists = False
    
    # Ochrana pred priamym pr√≠stupom k HTML s√∫borom
    if request.endpoint == 'static' and request.path.endswith('.html'):
        # Povolen√© HTML s√∫bory bez autentifik√°cie (login formul√°re)
        allowed_files = ['/login.html', '/register.html', '/login_2fa.html', '/setup_2fa.html', '/2fa_success.html']
        if request.path not in allowed_files:
            if not current_user.is_authenticated:
                return redirect(url_for('login'))
    
    if not g.user_exists and request.endpoint not in ['register', 'static']:
        return redirect(url_for('register'))

def add_log(level, message, device_ip=None):
    level_map = {'INFO': logging.INFO, 'SUCCESS': logging.INFO, 'WARNING': logging.WARNING, 'ERROR': logging.ERROR, 'DEBUG': logging.DEBUG}
    log_level_int = level_map.get(level.upper(), logging.INFO)
    logger.log(log_level_int, f"{f'[{device_ip}] ' if device_ip else ''}{message}")
    
    # Pokus o z√°pis do datab√°zy a WebSocket
    try:
        with get_db_connection() as conn:
            # Vklad√°me ƒçasov√∫ znaƒçku priamo z aplik√°cie
            conn.execute("INSERT INTO logs (timestamp, level, message, device_ip) VALUES (?, ?, ?, ?)", (datetime.now(), level, message, device_ip))
            conn.commit()
        
        # WebSocket emit s kontrolou pripojenia
        try:
            socketio.emit('log_update', {'level': level, 'message': message, 'device_ip': device_ip, 'timestamp': datetime.now().isoformat()})
        except Exception as ws_error:
            logger.warning(f"WebSocket emit pre log zlyhal: {ws_error}")
            
    except Exception as e:
        logger.error(f"Nepodarilo sa zap√≠sa≈• log do datab√°zy: {e}")
        # Aj pri chybe sa pok√∫sime odosla≈• cez WebSocket
        try:
            socketio.emit('log_update', {'level': 'error', 'message': f'Chyba pri z√°pise logu: {message}', 'device_ip': device_ip, 'timestamp': datetime.now().isoformat()})
        except:
            pass  # Ak ani WebSocket nefunguje, nevad√≠

def get_mikrotik_export_direct(ssh_client, ip, detailed_logging=True):
    try:
        if detailed_logging:
            add_log('info', "Z√≠skavam priamy SSH export...", ip)
        _, stdout, _ = ssh_client.exec_command('/export')
        export_content = stdout.read().decode('utf-8', errors='ignore')
        if not export_content:
            raise ValueError("Export command returned empty content.")
        if detailed_logging:
            add_log('info', "Priamy export √∫spe≈°ne z√≠skan√Ω.", ip)
        return export_content
    except Exception as e:
        add_log('error', f"Priamy SSH export zlyhal: {e}", ip)
        return None

def compare_with_local_backup(ip, remote_content, detailed_logging=True):
    try:
        # Hƒæad√°me najnov≈°√≠ .rsc s√∫bor pre dan√© IP s presn√Ωm patternom _ip_
        import re
        pattern = re.compile(f"_{ip}_\d{{8}}")
        local_backups = sorted(
            [f for f in os.listdir(BACKUP_DIR) if pattern.search(f) and f.endswith('.rsc')],
            reverse=True
        )
        if not local_backups:
            if detailed_logging:
                add_log('info', "≈Ωiadna lok√°lna z√°loha n√°jden√°. Vytv√°ram nov√∫.", ip)
            return True
        
        latest_backup_path = os.path.join(BACKUP_DIR, local_backups[0])
        with open(latest_backup_path, 'r', encoding='utf-8', errors='ignore') as f:
            local_content = f.read()
        
        # Ignore pravidl√° presne ako v legacy scripte (mikrotik_backup_compare_export_first.py)
        ignore_keywords = ['list=blacklist', 'comment=spamhaus,dshield,bruteforce']

        def normalized_lines(content):
            """Vr√°ti riadky bez ≈°umov√Ωch blacklist aktualiz√°ci√≠."""
            lines = content.splitlines()
            filtered = []
            skip_indented = False

            for raw_line in lines:
                stripped = raw_line.strip()

                # Ignorujeme v≈°etky komentov√© riadky, napr. ƒçasov√© hlaviƒçky.
                if stripped.startswith('#'):
                    continue

                if skip_indented:
                    if not stripped or raw_line[:1].isspace():
                        if not raw_line.rstrip().endswith('\\'):
                            skip_indented = False
                        continue
                    skip_indented = False

                if any(keyword in raw_line for keyword in ignore_keywords):
                    skip_indented = raw_line.rstrip().endswith('\\')
                    continue

                filtered.append(raw_line)

            return filtered

        local_lines = normalized_lines(local_content)
        remote_lines = normalized_lines(remote_content)
        
        # Pou≈æ√≠vame rovnak√∫ diff logiku ako p√¥vodn√Ω script
        d = difflib.Differ()
        diff = list(d.compare(local_lines, remote_lines))
        
        has_changes = any(line.startswith(('-', '+')) for line in diff)
        
        if has_changes:
            if detailed_logging:
                add_log('info', "Zisten√© zmeny v konfigur√°cii. Sp√∫≈°≈•am z√°lohu.", ip)
            return True
        else:
            if detailed_logging:
                add_log('info', "≈Ωiadne zmeny v konfigur√°cii. Z√°loha sa preskakuje.", ip)
            return False
    except Exception as e:
        # IP je u≈æ vo vizu√°lnom log prefixe, netreba ju v texte
        add_log('error', f"Chyba pri porovn√°van√≠ z√°loh: {e}", ip)
        return True

def run_backup_logic(device, is_sequential=False, result_holder=None):
    """Vykon√° z√°lohu dan√©ho zariadenia s pokroƒçil√Ωm logovan√≠m a kontrolou."""
    backup_performed = False  # ƒçi sme vytvorili nov√∫ z√°lohu a ≈•ahali ju z routera
    ftp_upload_success = False  # kumulat√≠vny v√Ωsledok oboch uploadov na FTP

    def update_results():
        if result_holder is not None:
            result_holder['backup_performed'] = backup_performed
            result_holder['ftp_uploaded'] = ftp_upload_success

    # Decrypt device password before use
    device = get_device_with_decrypted_password(device)
    ip, username, password, low_memory = device['ip'], device['username'], device['password'], device['low_memory']
    
    # Naƒç√≠tame nastavenie pre detailn√© logovanie
    with get_db_connection() as conn:
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
    
    detailed_logging = settings.get('backup_detailed_logging', 'false').lower() == 'true'

    # Zist√≠me n√°zov zariadenia (pre logy + notifik√°cie)
    device_name = device.get('name')
    if not device_name:
        try:
            with get_db_connection() as conn:
                row = conn.execute('SELECT name FROM devices WHERE ip = ?', (ip,)).fetchone()
                if row:
                    device_name = row['name']
        except Exception:
            device_name = None
    name_suffix = f" ({device_name})" if device_name else ""
    
    # Z√°kladn√° spr√°va o spusten√≠ z√°lohy (zjednoten√° pre konzistentnos≈•)
    # V≈ædy komunikujeme, ≈æe ide o pokroƒçil√∫ z√°lohu; pri sekvenƒçnej dopln√≠me info a pri low-memory re≈æime upozorn√≠me na dlh≈°ie ƒçasy
    # Neuv√°dzame IP priamo v texte (frontend ju m√° u≈æ v hlaviƒçke logu)
    prefix = "Z√°loha - " if is_sequential else ""
    if low_memory:
        add_log('info', f"{prefix}Sp√∫≈°≈•am z√°lohu{name_suffix} pre 16MB zariadenie (predƒ∫≈æen√© ƒçasy)", ip)
        if detailed_logging:
            add_log('info', "Re≈æim 16MB: predƒ∫≈æen√© ƒçakacie intervaly (backup ~30s, export ~180s).", ip)
    else:
        add_log('info', f"{prefix}Sp√∫≈°≈•am z√°lohu{name_suffix}", ip)
    
    socketio.emit('backup_status', {'ip': ip, 'id': device['id'], 'status': 'starting'})
    client = None
    try:
        client = paramiko.SSHClient()
        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        client.connect(ip, username=username, password=password, timeout=30)
        
        if detailed_logging:
            add_log('info', "SSH pripojenie √∫spe≈°ne.", ip)
        
        remote_config = get_mikrotik_export_direct(client, ip, detailed_logging)
        if remote_config is None:
            raise Exception("Nepodarilo sa z√≠ska≈• konfigur√°ciu na porovnanie.")
        if not compare_with_local_backup(ip, remote_config, detailed_logging):
            # Z√°vereƒçn√° spr√°va o preskoƒçen√≠ z√°lohy
            if is_sequential:
                add_log('info', f"Z√°loha - preskoƒçen√°{name_suffix} (≈æiadne zmeny){' (16MB)' if low_memory else ''}", ip)
            else:
                add_log('info', f"Z√°loha preskoƒçen√°{name_suffix} (≈æiadne zmeny){' (16MB)' if low_memory else ''}", ip)
            socketio.emit('backup_status', {'ip': ip, 'id': device['id'], 'status': 'skipped'})
            update_results()
            return
        _, stdout, _ = client.exec_command('/system identity print')
        identity_match = re.search(r'name:\s*(.+)', stdout.read().decode().strip())
        safe_identity = re.sub(r'[^a-zA-Z0-9_-]', '_', identity_match.group(1) if identity_match else ip)
        _, stdout, _ = client.exec_command('/file print where type=directory')
        has_flash = 'flash' in stdout.read().decode()
        
        if detailed_logging:
            add_log('info', f"Zariadenie {'m√°' if has_flash else 'nem√°'} /flash adres√°r.", ip)
            add_log('info', "Vykon√°vam cleanup v≈°etk√Ωch star√Ωch backup s√∫borov na zariaden√≠...", ip)
        
        # Vyma≈æ v≈°etky .backup s√∫bory (ale zachovaj in√© s√∫bory ako .rsc scripty, blacklists, atƒè.)
        cleanup_backup_command = ':foreach i in=[/file find where name~".backup"] do={/file remove $i}'
        client.exec_command(cleanup_backup_command)
        time.sleep(15)  # Dlh≈°ie ƒçakanie pre pomal√© zariadenia, ako v referenƒçnom scripte
        
        if detailed_logging:
            add_log('info', "Cleanup star√Ωch backup s√∫borov dokonƒçen√Ω.", ip)
        date_str = datetime.now().strftime("%Y%m%d-%H%M")
        base_filename = f"{safe_identity}_{ip}_{date_str}"
        backup_path = f"flash/{base_filename}.backup" if has_flash else f"{base_filename}.backup"
        rsc_path = f"flash/{base_filename}.rsc" if has_flash else f"{base_filename}.rsc"
        
        if detailed_logging:
            add_log('info', f"Vytv√°ram s√∫bory {base_filename}.backup a .rsc...", ip)
        
        client.exec_command(f'/system backup save name="{backup_path}" dont-encrypt=yes')
        if detailed_logging and low_memory:
            add_log('info', "ƒåak√°m (low-memory) 30s na dokonƒçenie /system backup save...", ip)
        time.sleep(30 if low_memory else 20)
        client.exec_command(f'/export file="{rsc_path}"')
        if detailed_logging and low_memory:
            add_log('info', "ƒåak√°m (low-memory) 180s na dokonƒçenie /export...", ip)
        time.sleep(180 if low_memory else 30)
        with client.open_sftp() as sftp:
            sftp.get(backup_path, os.path.join(BACKUP_DIR, f"{base_filename}.backup"))
            sftp.get(rsc_path, os.path.join(BACKUP_DIR, f"{base_filename}.rsc"))
            
            if detailed_logging:
                add_log('info', "S√∫bory √∫spe≈°ne stiahnut√©.", ip)
            
            sftp.remove(rsc_path)
        backup_performed = True
        with get_db_connection() as conn:
            conn.execute("UPDATE devices SET last_backup = CURRENT_TIMESTAMP WHERE id = ?", (device['id'],))
            conn.commit()
        
        # Z√°vereƒçn√° spr√°va o dokonƒçen√≠ z√°lohy
        if is_sequential:
            add_log('info', f"Z√°loha - dokonƒçen√°{name_suffix} √∫spe≈°ne{' (16MB)' if low_memory else ''}", ip)
        else:
            add_log('info', f"Z√°loha dokonƒçen√°{name_suffix}{' (16MB)' if low_memory else ''}.", ip)
        
        # Odoslanie notifik√°cie o √∫spe≈°nej z√°lohe
        with get_db_connection() as conn:
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
        if settings.get('notify_backup_success', 'false').lower() == 'true':
            device_name = device.get('name', ip)
            send_pushover_notification(
                f"üíæ Z√°loha MikroTik {ip} ({device_name}) bola √∫spe≈°ne dokonƒçen√°.",
                title="√öspe≈°n√° z√°loha",
                notification_key='notify_backup_success'
            )

        socketio.emit('backup_status', {'ip': ip, 'id': device['id'], 'status': 'success', 'last_backup': datetime.now(timezone.utc).isoformat()})
        upload_success_backup, error_backup = upload_to_ftp(
            os.path.join(BACKUP_DIR, f"{base_filename}.backup"),
            detailed_logging,
            device_ip=ip,
            log_success_entries=not is_sequential
        )
        upload_success_rsc, error_rsc = upload_to_ftp(
            os.path.join(BACKUP_DIR, f"{base_filename}.rsc"),
            detailed_logging,
            device_ip=ip,
            log_success_entries=not is_sequential
        )
        ftp_upload_success = upload_success_backup and upload_success_rsc
        if not ftp_upload_success:
            # Pushover upozornenie na zlyhanie uploadu (aj pri hromadn√Ωch z√°loh√°ch)
            try:
                error_details = '; '.join([err for err in [error_backup, error_rsc] if err])
                error_details = error_details or 'nezn√°ma chyba'
                if settings.get('notify_backup_failure', 'false').lower() == 'true':
                    send_pushover_notification(
                        f"‚ùå FTP upload z√°lohy zlyhal pre {ip}{name_suffix}: {error_details}",
                        title="Zlyhan√Ω FTP upload",
                        notification_key='notify_backup_failure'
                    )
            except Exception as e_push:
                add_log('error', f"Pushover notifik√°cia pre zlyhan√Ω FTP upload zlyhala: {e_push}", ip)
        if not is_sequential and ftp_upload_success:
            add_log('info', f"Z√°loha{name_suffix} nahrat√° na FTP server.", ip)

        # Vyƒçistenie star√Ωch z√°loh
        cleanup_old_backups(ip, settings, detailed_logging)

    except Exception as e:
        add_log('error', f"Chyba pri z√°lohe: {e}", ip)
        socketio.emit('backup_status', {'ip': ip, 'id': device['id'], 'status': 'error', 'message': str(e)})
        
        # Odoslanie notifik√°cie o ne√∫spechu z√°lohy
        try:
            with get_db_connection() as conn:
                settings_fail = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            if settings_fail.get('notify_backup_failure', 'false').lower() == 'true':
                device_name = device.get('name', ip)
                send_pushover_notification(
                    f"‚ùå Z√°loha MikroTik {ip} ({device_name}) zlyhala: {e}",
                    title="Zlyhan√° z√°loha",
                    notification_key='notify_backup_failure'
                )
        except Exception as notif_e:
            add_log('error', f"Notifik√°cia o zlyhan√≠ z√°lohy sa nepodarila: {notif_e}", ip)
    finally:
        update_results()
        if client: client.close()
        if ip in backup_tasks: del backup_tasks[ip]

def cleanup_old_backups(device_ip, settings, detailed_logging=True):
    """Vyƒçist√≠ star√© z√°lohy lok√°lne a na FTP serveri na z√°klade nastavenia."""
    try:
        # Naƒç√≠tame poƒçet uchov√°van√Ωch z√°loh z nastaven√≠, predvolen√° hodnota je 10
        retention_count = int(settings.get('backup_retention_count', 10))
        if detailed_logging:
            add_log('info', f"Sp√∫≈°≈•am ƒçistenie star√Ωch z√°loh, ponech√°vam posledn√Ωch {retention_count}.", device_ip)

        # Lok√°lne ƒçistenie
        file_pattern = f"_{device_ip}_"
        local_files = sorted([f for f in os.listdir(BACKUP_DIR) if file_pattern in f])
        
        # Keƒè≈æe m√°me .backup a .rsc, poƒçet s√∫borov je dvojn√°sobn√Ω
        if len(local_files) > retention_count * 2:
            files_to_delete = local_files[:-retention_count * 2]
            for f_del in files_to_delete:
                os.remove(os.path.join(BACKUP_DIR, f_del))
                if detailed_logging:
                    add_log('info', f"Lok√°lna z√°loha zmazan√°: {f_del}", device_ip)

        # FTP ƒçistenie
        if all(k in settings and settings[k] for k in ['ftp_server', 'ftp_username', 'ftp_password']):
            with FTP(settings['ftp_server']) as ftp:
                ftp.login(settings['ftp_username'], settings['ftp_password'])
                if 'ftp_directory' in settings and settings['ftp_directory']:
                    ftp.cwd(settings['ftp_directory'])
                
                ftp_files = sorted([f for f in ftp.nlst() if file_pattern in f])
                if len(ftp_files) > retention_count * 2:
                    files_to_delete_ftp = ftp_files[:-retention_count * 2]
                    for f_del in files_to_delete_ftp:
                        try:
                            ftp.delete(f_del)
                            if detailed_logging:
                                add_log('info', f"FTP z√°loha zmazan√°: {f_del}", device_ip)
                        except Exception as e_ftp_del:
                            add_log('error', f"Nepodarilo sa zmaza≈• FTP s√∫bor {f_del}: {e_ftp_del}", device_ip)
    except Exception as e:
        add_log('error', f"Chyba pri ƒçisten√≠ star√Ωch z√°loh pre {device_ip}: {e}", device_ip)

def get_snmp_data(ip, community='public'):
    oids = {
        'identity': '1.3.6.1.2.1.1.5.0',
        'uptime': '1.3.6.1.2.1.1.3.0',
        'version': '1.3.6.1.4.1.14988.1.1.4.4.0',
        'board_name': '1.3.6.1.4.1.14988.1.1.7.8.0',
        # Ponech√°me p√¥vodn√Ω bodov√Ω OID pre CPU load (prv√Ω index), ale ni≈æ≈°ie ho nahrad√≠me priemerom z tabuƒæky
        'cpu_load': '1.3.6.1.2.1.25.3.3.1.2.1',
        'temperature': '1.3.6.1.4.1.14988.1.1.3.11.0',
        'cpu_count': '1.3.6.1.4.1.14988.1.1.3.8.0',  # MikroTik ≈°pecifick√Ω OID pre CPU count (fallback)
        'architecture': '1.3.6.1.4.1.14988.1.1.7.7.0',
        # Memory OIDy pre hAP AX (z CLI v√Ωstupu)
        'used_memory': '1.3.6.1.2.1.25.2.3.1.6.65536',   # used-memory z CLI
        'total_memory': '1.3.6.1.2.1.25.2.3.1.5.65536',  # total-memory z CLI
    }
    results = {}
    try:
        from pysnmp.hlapi import getCmd, nextCmd, SnmpEngine, CommunityData, UdpTransportTarget, ContextData, ObjectType, ObjectIdentity
        from datetime import timedelta
        import time
        
        HRPROCESSORLOAD_TABLE = '1.3.6.1.2.1.25.3.3.1.2'
        
        # CPU friendly processing - mal√© pauzy medzi OID requestmi
        # Optimalizovan√© pre offline zariadenia - skr√°ten√© timeouty
        for i, (name, oid) in enumerate(oids.items()):
            # Prid√°me mal√∫ pauzu ka≈æd√© 3 OIDy pre zn√≠≈æenie CPU z√°≈•a≈æe
            if i > 0 and i % 3 == 0:
                time.sleep(0.1)  # 100ms pauza
                
            # Skr√°ten√© timeouty pre r√Ωchlej≈°ie detekciu offline zariaden√≠: 2s timeout, 1 pokus
            errorIndication, errorStatus, _, varBinds = next(getCmd(SnmpEngine(),CommunityData(community,mpModel=0),UdpTransportTarget((ip,161),timeout=2,retries=1),ContextData(),ObjectType(ObjectIdentity(oid))))
            
            if errorIndication or errorStatus: 
                results[name] = 'N/A'
                # Early exit pre offline zariadenia - ak zlyh√° uptime (prv√Ω kritick√Ω test), nemus√≠me testova≈• ƒèal≈°ie OIDy
                if name == 'uptime':
                    # Vypln√≠me zost√°vaj√∫ce hodnoty ako N/A a skonƒç√≠me
                    for remaining_name in list(oids.keys())[i+1:]:
                        results[remaining_name] = 'N/A'
                    break
            else:
                val = varBinds[0][1]
                if name == 'uptime':
                    seconds = int(float(val) / 100.0)
                    td = timedelta(seconds=seconds)
                    results[name] = f"{td.days}d {td.seconds//3600}h {(td.seconds//60)%60}m"
                    results['uptime_seconds'] = str(seconds)
                elif name == 'temperature': 
                    results[name] = str(int(int(val)/10.0))
                elif name in ['used_memory', 'total_memory']:
                    # Memory hodnoty s√∫ v KB, konvertujeme na MB
                    try:
                        mb_value = int(val) / 1024
                        results[name] = str(round(mb_value))  # Zaokr√∫hlenie na cel√© MB
                    except:
                        results[name] = 'N/A'
                else: 
                    results[name] = str(val)
        
        # Ak zariadenie odpovedalo (m√°me uptime), dopoƒç√≠tame CPU count a priemern√Ω load zo ≈°tandardnej tabuƒæky hrProcessorLoad
        if results.get('uptime') and results.get('uptime') != 'N/A':
            try:
                core_loads = []
                core_count = 0
                for (errInd, errStat, _, varBinds) in nextCmd(
                    SnmpEngine(),
                    CommunityData(community, mpModel=0),
                    UdpTransportTarget((ip, 161), timeout=2, retries=1),
                    ContextData(),
                    ObjectType(ObjectIdentity(HRPROCESSORLOAD_TABLE)),
                    lexicographicMode=False
                ):
                    if errInd or errStat:
                        break
                    for oid, val in varBinds:
                        # Over√≠me, ≈æe naozaj prech√°dzame spr√°vnou tabuƒækou
                        if str(oid).startswith(HRPROCESSORLOAD_TABLE + '.'):
                            core_count += 1
                            try:
                                core_loads.append(int(val))
                            except:
                                pass
                if core_count > 0:
                    # Priemer CPU load zo v≈°etk√Ωch jadier (ak dostupn√©)
                    if core_loads:
                        avg_load = int(round(sum(core_loads) / len(core_loads)))
                        results['cpu_load'] = str(avg_load)
                    # Pou≈æijeme poƒçet jadier z hrProcessorLoad tabuƒæky ako zdroj pravdy
                    results['cpu_count'] = str(core_count)
            except Exception as e:
                pass  # Ticho preskoƒçi≈• chyby SNMP
        
        # Vypoƒç√≠taj free memory a memory usage percentage
        if results.get('used_memory') != 'N/A' and results.get('total_memory') != 'N/A':
            try:
                # Hodnoty s√∫ u≈æ v MB po konverzii vy≈°≈°ie
                used_mb = int(results['used_memory'])
                total_mb = int(results['total_memory'])
                free_mb = total_mb - used_mb
                usage_percent = int((used_mb / total_mb) * 100)
                
                # Ulo≈æi≈• hodnoty v MB
                results['free_memory'] = str(free_mb)
                results['memory_usage'] = str(usage_percent)
                
            except Exception as e:
                results['free_memory'] = 'N/A'
                results['memory_usage'] = 'N/A'
        else:
            # Fallback estimation ak OIDy nefunguj√∫ - ale len pre online zariadenia
            if results.get('uptime') and results.get('uptime') != 'N/A':
                try:
                    total_mb = int(results.get('total_memory')) if results.get('total_memory') not in [None, 'N/A'] else 1024
                except (ValueError, TypeError):
                    total_mb = 1024
                try:
                    used_mb = int(results.get('used_memory')) if results.get('used_memory') not in [None, 'N/A'] else 569
                except (ValueError, TypeError):
                    used_mb = 569
                free_mb = max(total_mb - used_mb, 0)
                usage_percent = int((used_mb / total_mb) * 100) if total_mb else 0
                
                results['total_memory'] = str(total_mb)
                results['used_memory'] = str(used_mb)
                results['free_memory'] = str(free_mb)
                results['memory_usage'] = str(usage_percent)
            else:
                # Offline zariadenia - ponech√°me N/A, aby sa nevytv√°rali falo≈°n√© body
                results['total_memory'] = 'N/A'
                results['used_memory'] = 'N/A'
                results['free_memory'] = 'N/A'
                results['memory_usage'] = 'N/A'
        
        # Odstr√°nime pomocn√© polia, ktor√© nechceme zobrazova≈•
        for key in ['architecture']:
            if key in results: 
                del results[key]
        if 'uptime_seconds' not in results:
            results['uptime_seconds'] = '0'
        return results
    except Exception as e:
        add_log('error', f"SNMP query for IP {ip} failed: {e}", device_ip=ip)
        fallback = {k: 'N/A' for k in ['identity','uptime','version','board_name','cpu_load','temperature','cpu_count','memory_usage','used_memory','total_memory','free_memory']}
        fallback['uptime_seconds'] = '0'
        return fallback

def upload_to_ftp(local_path, detailed_logging=True, device_ip=None, log_success_entries=True):
    def parse_int(value, default):
        try:
            return int(value)
        except (TypeError, ValueError):
            return default

    def attempt_upload(settings):
        try:
            server = settings.get('ftp_server')
            username = settings.get('ftp_username')
            password = settings.get('ftp_password')
            if not (server and username and password):
                return False, "Ch√Ωbaj√∫ FTP nastavenia (server/pou≈æ√≠vateƒæ/heslo)."
            port = parse_int(settings.get('ftp_port'), 21)
            with FTP() as ftp:
                ftp.connect(server, port)
                ftp.login(username, password)
                if settings.get('ftp_directory'):
                    ftp.cwd(settings['ftp_directory'])
                with open(local_path, 'rb') as f:
                    ftp.storbinary(f'STOR {os.path.basename(local_path)}', f)
            return True, None
        except Exception as e:
            return False, str(e)

    with get_db_connection() as conn:
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings WHERE key LIKE \"ftp_%\"')}

    success, error_msg = attempt_upload(settings)
    if success:
        if log_success_entries:
            add_log('info', f"S√∫bor {os.path.basename(local_path)} nahrat√Ω na FTP server.", device_ip)
        return True, None

    add_log('error', f"FTP upload zlyhal: {error_msg}", device_ip)
    return False, error_msg

def send_pushover_notification(message, title="MikroTik Manager", notification_key=None, default_enabled=True):
    try:
        queried_keys = ['pushover_app_key', 'pushover_user_key', 'quiet_hours_enabled', 'quiet_hours_start', 'quiet_hours_end']
        if notification_key:
            queried_keys.append(notification_key)
        with get_db_connection() as conn:
            cursor = conn.cursor()
            placeholders = ','.join('?' for _ in queried_keys)
            settings_rows = cursor.execute(f'SELECT key, value FROM settings WHERE key IN ({placeholders})', queried_keys).fetchall()
            settings = {row['key']: row['value'] for row in settings_rows}
            
            enabled = True
            if notification_key:
                raw_value = settings.get(notification_key)
                if raw_value is None:
                    cursor.execute("INSERT OR IGNORE INTO settings (key, value) VALUES (?, ?)", (notification_key, 'true' if default_enabled else 'false'))
                    conn.commit()
                    enabled = default_enabled
                else:
                    enabled = raw_value.lower() == 'true'
                if not enabled:
                    debug_log('debug_notifications', f"Notification '{notification_key}' potlaƒçen√° - vypnut√° v nastaveniach.")
                    return False
            
            # Quiet hours support
            quiet_enabled = settings.get('quiet_hours_enabled', 'false').lower() == 'true'
            if quiet_enabled:
                start = settings.get('quiet_hours_start')
                end = settings.get('quiet_hours_end')
                if start and end:
                    try:
                        start_time = datetime.strptime(start, "%H:%M").time()
                        end_time = datetime.strptime(end, "%H:%M").time()
                        now_time = datetime.now().time()
                        in_quiet_hours = False
                        if start_time <= end_time:
                            in_quiet_hours = start_time <= now_time < end_time
                        else:
                            in_quiet_hours = now_time >= start_time or now_time < end_time
                        if in_quiet_hours:
                            debug_log('debug_notifications', f"Notification '{notification_key}' potlaƒçen√° - quiet hours.")
                            return False
                    except Exception as time_e:
                        debug_log('debug_notifications', f"Quiet hours parsing error: {time_e}")
            
            app_key = settings.get('pushover_app_key')
            user_key = settings.get('pushover_user_key')
            if not app_key or not user_key:
                debug_log('debug_notifications', "Pushover notifik√°cia neodoslan√° - ch√Ωba app key alebo user key.")
                return False
        
        conn_pushover = http.client.HTTPSConnection("api.pushover.net:443")
        conn_pushover.request(
            "POST",
            "/1/messages.json",
            urllib.parse.urlencode({"token": app_key, "user": user_key, "title": title, "message": message}),
            {"Content-type": "application/x-www-form-urlencoded"}
        )
        conn_pushover.getresponse()
        
        level_map = {
            'notify_device_offline': 'warning',
            'notify_backup_failure': 'error'
        }
        log_level = level_map.get(notification_key, 'info')
        add_log(log_level, f"Pushover notifik√°cia odoslan√°: {message}")
        return True
    except Exception as e:
        add_log('error', f"Odoslanie Pushover notifik√°cie zlyhalo: {e}")
        return False

@app.route('/register', methods=['GET', 'POST'])
def register():
    if g.get('user_exists', True):
        return redirect(url_for('login'))
    error = None
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        password_confirm = request.form.get('password_confirm')
        if not username or not password:
            error = 'Meno a heslo s√∫ povinn√©.'
        elif len(password) < 8:
            error = 'Heslo mus√≠ ma≈• aspo≈à 8 znakov.'
        elif password != password_confirm:
            error = 'Hesl√° sa nezhoduj√∫.'
        else:
            with get_db_connection() as conn:
                password_hash = generate_password_hash(password)
                totp_secret = pyotp.random_base32()
                cursor = conn.cursor()
                cursor.execute('INSERT INTO users (username, password, totp_secret, totp_enabled) VALUES (?, ?, ?, ?)',
                             (username, password_hash, totp_secret, 0))
                user_id = cursor.lastrowid
                conn.commit()
                user = load_user(user_id)
                login_user(user)
                return redirect(url_for('setup_2fa'))
    return render_template('register.html', error=error)

@app.route('/login', methods=['GET', 'POST'])
def login():
    if current_user.is_authenticated:
        return redirect(url_for('index'))
    error = None
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        with get_db_connection() as conn:
            user_data = conn.execute('SELECT * FROM users WHERE username = ?', (username,)).fetchone()
        if user_data and check_password_hash(user_data['password'], password):
            user = load_user(user_data['id'])
            if user.totp_enabled:
                session['2fa_user_id'] = user.id
                return redirect(url_for('login_2fa'))
            else:
                login_user(user)
                return redirect(url_for('setup_2fa'))
        else:
            error = 'Neplatn√© meno alebo heslo.'
            time.sleep(1)
    return render_template('login.html', error=error)

@app.route('/login/2fa', methods=['GET', 'POST'])
def login_2fa():
    if '2fa_user_id' not in session:
        return redirect(url_for('login'))
    error = None
    if request.method == 'POST':
        user = load_user(session['2fa_user_id'])
        totp_code = request.form.get('totp_code', '').strip()
        backup_code = request.form.get('backup_code', '').strip()
        
        if totp_code:
            # Overenie TOTP k√≥du z aplik√°cie
            if pyotp.TOTP(user.totp_secret).verify(totp_code):
                login_user(user, remember=True)
                session.permanent = True
                session.pop('2fa_user_id', None)
                return redirect(request.args.get('next') or url_for('index'))
            else:
                error = 'Neplatn√Ω overovac√≠ k√≥d z aplik√°cie.'
        elif backup_code:
            # Overenie z√°lo≈æn√©ho k√≥du
            try:
                with get_db_connection() as conn:
                    backup_record = conn.execute(
                        'SELECT id FROM backup_codes WHERE user_id = ? AND code = ? AND used = 0', 
                        (user.id, backup_code)
                    ).fetchone()
                    
                    if backup_record:
                        # Oznaƒçenie k√≥du ako pou≈æit√©ho
                        conn.execute(
                            'UPDATE backup_codes SET used = 1, used_at = ? WHERE id = ?',
                            (datetime.now(), backup_record['id'])
                        )
                        conn.commit()
                        
                        login_user(user, remember=True)
                        session.permanent = True
                        session.pop('2fa_user_id', None)
                        add_log('info', f"Pou≈æ√≠vateƒæ '{user.username}' sa prihl√°sil pomocou z√°lo≈æn√©ho k√≥du.")
                        return redirect(request.args.get('next') or url_for('index'))
                    else:
                        error = 'Neplatn√Ω alebo u≈æ pou≈æit√Ω z√°lo≈æn√Ω k√≥d.'
            except Exception as e:
                logger.error(f"Chyba pri overen√≠ z√°lo≈æn√©ho k√≥du: {e}")
                error = 'Chyba pri overen√≠ z√°lo≈æn√©ho k√≥du.'
        else:
            error = 'Zadajte buƒè k√≥d z aplik√°cie alebo z√°lo≈æn√Ω k√≥d.'
    
    return render_template('login_2fa.html', error=error)

@app.route('/setup-2fa')
@login_required
def setup_2fa():
    if current_user.totp_enabled:
        return redirect(url_for('index'))
    secret = current_user.totp_secret
    uri = pyotp.totp.TOTP(secret).provisioning_uri(name=current_user.username, issuer_name="MikroTik Manager")
    img = qrcode.make(uri)
    buf = BytesIO()
    img.save(buf)
    qr_code_data = base64.b64encode(buf.getvalue()).decode('ascii')
    return render_template('setup_2fa.html', qr_code=qr_code_data)

@app.route('/verify-2fa', methods=['POST'])
@login_required
def verify_2fa():
    totp_code = request.form.get('totp_code', '').strip()
    if pyotp.TOTP(current_user.totp_secret).verify(totp_code):
        with get_db_connection() as conn:
            conn.execute('UPDATE users SET totp_enabled = 1 WHERE id = ?', (current_user.id,))
            conn.commit()
        return redirect(url_for('index'))
    else:
        secret = current_user.totp_secret
        uri = pyotp.totp.TOTP(secret).provisioning_uri(name=current_user.username, issuer_name="MikroTik Manager")
        img = qrcode.make(uri)
        buf = BytesIO()
        img.save(buf)
        qr_code_data = base64.b64encode(buf.getvalue()).decode('ascii')
        return render_template('setup_2fa.html', qr_code=qr_code_data, error="Neplatn√Ω k√≥d, sk√∫ste to znova.")

@app.route('/logout')
@login_required
def logout():
    logout_user()
    return redirect(url_for('login'))

@app.route('/backups')
@login_required
def list_backups():
    """Dynamick√Ω v√Ωpis z√°loh: zoraden√© podƒæa mtime (najnov≈°ie prv√©)."""
    try:
        entries = []
        for filename in os.listdir(BACKUP_DIR):
            filepath = os.path.join(BACKUP_DIR, filename)
            if os.path.isfile(filepath):
                try:
                    mtime = os.path.getmtime(filepath)
                    entries.append({
                        'name': filename,
                        'size': os.path.getsize(filepath),
                        'modified': datetime.fromtimestamp(mtime),
                        '_mtime': mtime
                    })
                except OSError:
                    continue
        # Server-side zoradenie podƒæa mtime desc
        entries.sort(key=lambda x: x['_mtime'], reverse=True)
        # Odstr√°≈à pomocn√Ω kƒæ√∫ƒç
        for e in entries:
            e.pop('_mtime', None)
        return render_template('backups.html', files=entries)
    except Exception as e:
        logger.error(f"Chyba pri naƒç√≠tan√≠ zoznamu z√°loh: {e}")
        return "Chyba pri naƒç√≠tan√≠ zoznamu z√°loh.", 500

@app.route('/download_backup/<path:filename>')
@login_required
def download_backup(filename):
    try:
        return send_from_directory(BACKUP_DIR, filename, as_attachment=True)
    except FileNotFoundError:
        return "S√∫bor nebol n√°jden√Ω.", 404
    except Exception as e:
        logger.error(f"Chyba pri s≈•ahovan√≠ s√∫boru '{filename}': {e}")
        return "Chyba pri s≈•ahovan√≠ s√∫boru.", 500

@app.route('/api/delete_backup/<path:filename>', methods=['DELETE'])
@login_required
def delete_backup(filename):
    """API endpoint pre vymazanie z√°lo≈æn√©ho s√∫boru lok√°lne aj z FTP servera."""
    try:
        # Bezpeƒçnostn√° kontrola - povoli≈• iba .backup a .rsc s√∫bory
        if not (filename.endswith('.backup') or filename.endswith('.rsc')):
            return jsonify({'status': 'error', 'message': 'Nepovolen√Ω typ s√∫boru.'}), 400
        
        # Z√≠skanie z√°kladn√©ho n√°zvu s√∫boru bez pr√≠pony
        base_filename = os.path.splitext(filename)[0]
        backup_file = base_filename + '.backup'
        rsc_file = base_filename + '.rsc'
        
        # Zoznam s√∫borov na vymazanie
        files_to_delete = []
        if os.path.exists(os.path.join(BACKUP_DIR, backup_file)):
            files_to_delete.append(backup_file)
        if os.path.exists(os.path.join(BACKUP_DIR, rsc_file)):
            files_to_delete.append(rsc_file)
        
        deleted_local = []
        deleted_ftp = []
        
        # Vymazanie lok√°lnych s√∫borov
        for file_to_delete in files_to_delete:
            local_file_path = os.path.join(BACKUP_DIR, file_to_delete)
            try:
                os.remove(local_file_path)
                deleted_local.append(file_to_delete)
            except Exception as e:
                add_log('warning', f"Nepodarilo sa vymaza≈• lok√°lny s√∫bor {file_to_delete}: {e}")
        
        # Pokus o vymazanie z FTP servera
        try:
            with get_db_connection() as conn:
                settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            
            # Kontrola FTP nastaven√≠
            if all(k in settings and settings[k] for k in ['ftp_server', 'ftp_username', 'ftp_password']):
                from ftplib import FTP
                with FTP(settings['ftp_server']) as ftp:
                    ftp.login(settings['ftp_username'], settings['ftp_password'])
                    
                    # Ak je nastaven√Ω adres√°r, prejdeme do≈à
                    if 'ftp_directory' in settings and settings['ftp_directory']:
                        ftp.cwd(settings['ftp_directory'])
                    
                    # Pokus o vymazanie oboch s√∫borov z FTP
                    for file_to_delete in files_to_delete:
                        try:
                            ftp.delete(file_to_delete)
                            deleted_ftp.append(file_to_delete)
                        except Exception as ftp_e:
                            # Ignoruj chyby ak s√∫bor neexistuje na FTP
                            pass
        except Exception as ftp_connection_e:
            add_log('warning', f"Nepodarilo sa pripoji≈• na FTP server pre vymazanie s√∫borov: {ftp_connection_e}")
        
        # Vytvorenie zl√∫ƒçen√Ωch log spr√°v
        if deleted_local:
            local_files_str = ', '.join(deleted_local)
            if deleted_ftp:
                ftp_files_str = ', '.join(deleted_ftp)
                add_log('info', f"Z√°lo≈æn√© s√∫bory vymazan√© lok√°lne aj z FTP: {local_files_str}")
            else:
                add_log('info', f"Z√°lo≈æn√© s√∫bory vymazan√© lok√°lne: {local_files_str}")
        
        # Aktualiz√°cia datab√°zy - kontrola ƒçi po vymazan√≠ s√∫boru e≈°te existuj√∫ z√°lohy pre zariadenie
        try:
            # Extrakcia IP adresy zo s√∫boru (form√°t: RouterName_IP_timestamp.backup)
            import re
            ip_match = re.search(r'_(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})_', filename)
            if ip_match:
                device_ip = ip_match.group(1)
                
                # Kontrola, ƒçi e≈°te existuj√∫ nejak√© z√°lohy pre toto zariadenie
                candidate_files = []
                for f in os.listdir(BACKUP_DIR):
                    if not f.endswith('.backup') or device_ip not in f:
                        continue
                    full_path = os.path.join(BACKUP_DIR, f)
                    if os.path.isfile(full_path):
                        candidate_files.append((f, full_path, os.path.getmtime(full_path)))

                with get_db_connection() as conn:
                    if not candidate_files:
                        conn.execute('UPDATE devices SET last_backup = NULL WHERE ip = ?', (device_ip,))
                    else:
                        latest_name, latest_path, latest_mtime = max(candidate_files, key=lambda item: item[2])
                        latest_mtime = datetime.fromtimestamp(latest_mtime)
                        conn.execute('UPDATE devices SET last_backup = ? WHERE ip = ?', (latest_mtime, device_ip,))
                    conn.commit()
        except Exception as db_e:
            add_log('warning', f"Nepodarilo sa aktualizova≈• datab√°zu po vymazan√≠ z√°lohy: {db_e}")
        
        # Vytvorenie odpovede
        all_deleted = deleted_local + deleted_ftp
        if all_deleted:
            unique_deleted = list(set(all_deleted))  # Odstr√°nenie duplik√°tov
            message = f"S√∫bory √∫spe≈°ne vymazan√©: {', '.join(unique_deleted)}"
            return jsonify({'status': 'success', 'message': message})
        else:
            return jsonify({'status': 'warning', 'message': 'S√∫bory neboli n√°jden√© ani lok√°lne ani na FTP serveri.'}), 404
            
    except Exception as e:
        logger.error(f"Chyba pri vymaz√°van√≠ z√°lo≈æn√©ho s√∫boru '{filename}': {e}")
        add_log('error', f"Chyba pri vymaz√°van√≠ z√°lo≈æn√©ho s√∫boru {filename}: {e}")
        return jsonify({'status': 'error', 'message': f'Chyba pri vymaz√°van√≠ s√∫boru: {str(e)}'}), 500

@app.route('/')
@login_required
def index():
    if not current_user.totp_enabled:
        return redirect(url_for('setup_2fa'))
    
    # Detekcia Android WebView pre optimaliz√°ciu
    user_agent = request.headers.get('User-Agent', '')
    is_android_webview = 'wv' in user_agent or 'Android' in user_agent
    
    # Logovanie proxy inform√°ci√≠ pre debugging
    forwarded_for = request.headers.get('X-Forwarded-For', 'N/A')
    forwarded_proto = request.headers.get('X-Forwarded-Proto', 'N/A')
    real_ip = request.remote_addr
    
    if is_android_webview:
        logger.info(f"Android WebView pr√≠stup - User: {current_user.username}, "
                   f"IP: {real_ip}, X-Forwarded-For: {forwarded_for}, "
                   f"Proto: {forwarded_proto}, UA: {user_agent[:100]}")
    
    return send_from_directory('.', 'index.html')

@app.route('/monitoring.html')
@login_required
def monitoring():
    if not current_user.totp_enabled:
        return redirect(url_for('setup_2fa'))
    return send_from_directory('.', 'monitoring.html')

@app.route('/backups.html')
@login_required
def backups_page():
    """Presmerovanie na dynamick√∫ route, aby sa v≈ædy zobrazili aktu√°lne a spr√°vne zoraden√© d√°ta."""
    if not current_user.totp_enabled:
        return redirect(url_for('setup_2fa'))
    return redirect(url_for('list_backups'))

@app.route('/settings.html')
@login_required
def settings_page():
    if not current_user.totp_enabled:
        return redirect(url_for('setup_2fa'))
    return send_from_directory('.', 'settings.html')

@app.route('/api/user/status')
@login_required
def user_status():
    return jsonify({'username': current_user.username})

@app.route('/api/user/change-password', methods=['POST'])
@login_required
def change_password():
    data = request.json
    old_password = data.get('old_password')
    new_password = data.get('new_password')
    new_password_confirm = data.get('new_password_confirm')

    if not all([old_password, new_password, new_password_confirm]):
        return jsonify({'status': 'error', 'message': 'V≈°etky polia s√∫ povinn√©.'}), 400

    with get_db_connection() as conn:
        user_data = conn.execute('SELECT password FROM users WHERE id = ?', (current_user.id,)).fetchone()

    if not user_data or not check_password_hash(user_data['password'], old_password):
        return jsonify({'status': 'error', 'message': 'Star√© heslo nie je spr√°vne.'}), 400

    if new_password != new_password_confirm:
        return jsonify({'status': 'error', 'message': 'Nov√© hesl√° sa nezhoduj√∫.'}), 400
    
    if len(new_password) < 8:
        return jsonify({'status': 'error', 'message': 'Nov√© heslo mus√≠ ma≈• aspo≈à 8 znakov.'}), 400

    new_password_hash = generate_password_hash(new_password)
    with get_db_connection() as conn:
        conn.execute('UPDATE users SET password = ? WHERE id = ?', (new_password_hash, current_user.id))
        conn.commit()
    
    add_log('info', f"Pou≈æ√≠vateƒæ '{current_user.username}' si zmenil heslo.")
    return jsonify({'status': 'success', 'message': 'Heslo bolo √∫spe≈°ne zmenen√©.'})

@app.route('/api/user/change-username', methods=['POST'])
@login_required
def change_username():
    data = request.json
    new_username = data.get('new_username')
    password = data.get('password')

    if not all([new_username, password]):
        return jsonify({'status': 'error', 'message': 'V≈°etky polia s√∫ povinn√©.'}), 400

    # Valid√°cia pou≈æ√≠vateƒæsk√©ho mena
    if len(new_username) < 3:
        return jsonify({'status': 'error', 'message': 'Pou≈æ√≠vateƒæsk√© meno mus√≠ ma≈• aspo≈à 3 znaky.'}), 400
    
    if len(new_username) > 50:
        return jsonify({'status': 'error', 'message': 'Pou≈æ√≠vateƒæsk√© meno m√¥≈æe ma≈• maxim√°lne 50 znakov.'}), 400
    
    # Povolen√© znaky: p√≠smen√°, ƒç√≠slice, podƒçiarkovn√≠k a pomlƒçka
    import re
    if not re.match('^[a-zA-Z0-9_-]+$', new_username):
        return jsonify({'status': 'error', 'message': 'Pou≈æ√≠vateƒæsk√© meno m√¥≈æe obsahova≈• len p√≠smen√°, ƒç√≠slice, podƒçiarkovn√≠k a pomlƒçku.'}), 400

    with get_db_connection() as conn:
        # Overenie hesla
        user_data = conn.execute('SELECT password FROM users WHERE id = ?', (current_user.id,)).fetchone()
        if not user_data or not check_password_hash(user_data['password'], password):
            return jsonify({'status': 'error', 'message': 'Heslo nie je spr√°vne.'}), 400

        # Kontrola, ƒçi pou≈æ√≠vateƒæsk√© meno u≈æ existuje
        existing_user = conn.execute('SELECT id FROM users WHERE username = ? AND id != ?', (new_username, current_user.id)).fetchone()
        if existing_user:
            return jsonify({'status': 'error', 'message': 'Pou≈æ√≠vateƒæsk√© meno u≈æ existuje.'}), 400

        # Ulo≈æenie star√©ho mena pre log
        old_username = current_user.username
        
        # Aktualiz√°cia pou≈æ√≠vateƒæsk√©ho mena
        conn.execute('UPDATE users SET username = ? WHERE id = ?', (new_username, current_user.id))
        conn.commit()
    
    # Aktualiz√°cia objektu aktu√°lneho pou≈æ√≠vateƒæa
    current_user.username = new_username
    
    add_log('info', f"Pou≈æ√≠vateƒæ '{old_username}' si zmenil pou≈æ√≠vateƒæsk√© meno na '{new_username}'.")
    return jsonify({'status': 'success', 'message': f'Pou≈æ√≠vateƒæsk√© meno bolo √∫spe≈°ne zmenen√© na "{new_username}".'})

@app.route('/api/user/backup-codes', methods=['GET', 'POST'])
@login_required
def handle_backup_codes():
    """Spracovanie z√°lo≈æn√Ωch k√≥dov pre 2FA"""
    if not current_user.totp_enabled:
        return jsonify({'status': 'error', 'message': '2FA nie je aktivovan√© pre tento √∫ƒçet.'}), 403
    
    if request.method == 'GET':
        # Vr√°ti poƒçet zost√°vaj√∫cich z√°lo≈æn√Ωch k√≥dov
        try:
            with get_db_connection() as conn:
                count = conn.execute('SELECT COUNT(*) FROM backup_codes WHERE user_id = ? AND used = 0', (current_user.id,)).fetchone()[0]
                return jsonify({'remaining_codes': count})
        except Exception as e:
            logger.error(f"Chyba pri z√≠skavan√≠ poƒçtu z√°lo≈æn√Ωch k√≥dov: {e}")
            return jsonify({'status': 'error', 'message': 'Chyba pri naƒç√≠tavan√≠ stavu z√°lo≈æn√Ωch k√≥dov.'}), 500
    
    elif request.method == 'POST':
        # Generuje nov√© z√°lo≈æn√© k√≥dy
        data = request.json
        password = data.get('password')
        
        if not password:
            return jsonify({'status': 'error', 'message': 'Heslo je povinn√©.'}), 400
        
        # Overenie hesla
        with get_db_connection() as conn:
            user_data = conn.execute('SELECT password FROM users WHERE id = ?', (current_user.id,)).fetchone()
        
        if not user_data or not check_password_hash(user_data['password'], password):
            return jsonify({'status': 'error', 'message': 'Nespr√°vne heslo.'}), 401
        
        try:
            # Generovanie 10 nov√Ωch z√°lo≈æn√Ωch k√≥dov (kompletn√° sada)
            import secrets
            import string
            
            backup_codes = []
            for _ in range(10):
                # Generuje k√≥d vo form√°te XXX123-YYY456
                part1 = ''.join(secrets.choice(string.ascii_uppercase + string.digits) for _ in range(6))
                part2 = ''.join(secrets.choice(string.ascii_uppercase + string.digits) for _ in range(6))
                code = f"{part1[:3]}{part1[3:]}-{part2[:3]}{part2[3:]}"
                backup_codes.append(code)
            
            # Ulo≈æenie do datab√°zy (nahradenie star√Ωch k√≥dov)
            with get_db_connection() as conn:
                # Vymazanie star√Ωch k√≥dov
                conn.execute('DELETE FROM backup_codes WHERE user_id = ?', (current_user.id,))
                
                # Pridanie nov√Ωch k√≥dov
                for code in backup_codes:
                    conn.execute('INSERT INTO backup_codes (user_id, code, created_at, used) VALUES (?, ?, ?, 0)', 
                               (current_user.id, code, datetime.now()))
                conn.commit()
            
            add_log('info', f"Pou≈æ√≠vateƒæ '{current_user.username}' vygeneroval nov√© z√°lo≈æn√© k√≥dy.")
            return jsonify({'status': 'success', 'backup_codes': backup_codes})
            
        except Exception as e:
            logger.error(f"Chyba pri generovan√≠ z√°lo≈æn√Ωch k√≥dov: {e}")
            return jsonify({'status': 'error', 'message': 'Chyba pri generovan√≠ z√°lo≈æn√Ωch k√≥dov.'}), 500

@app.route('/api/user/disable-2fa', methods=['POST'])
@login_required
def disable_2fa():
    """Vypnutie 2FA - len v n√∫dzov√Ωch pr√≠padoch"""
    data = request.json
    password = data.get('password')
    
    if not password:
        return jsonify({'status': 'error', 'message': 'Heslo je povinn√©.'}), 400
    
    # Overenie hesla
    with get_db_connection() as conn:
        user_data = conn.execute('SELECT password FROM users WHERE id = ?', (current_user.id,)).fetchone()
    
    if not user_data or not check_password_hash(user_data['password'], password):
        return jsonify({'status': 'error', 'message': 'Nespr√°vne heslo.'}), 401
    
    try:
        with get_db_connection() as conn:
            # Vypnutie 2FA
            conn.execute('UPDATE users SET totp_enabled = 0 WHERE id = ?', (current_user.id,))
            # Vymazanie v≈°etk√Ωch z√°lo≈æn√Ωch k√≥dov
            conn.execute('DELETE FROM backup_codes WHERE user_id = ?', (current_user.id,))
            conn.commit()
        
        add_log('warning', f"Pou≈æ√≠vateƒæ '{current_user.username}' vypnul 2FA!")
        return jsonify({'status': 'success', 'message': '2FA bolo vypnut√©. D√¥razne odpor√∫ƒçame ho znovu aktivova≈•.'})
        
    except Exception as e:
        logger.error(f"Chyba pri vyp√≠nan√≠ 2FA: {e}")
        return jsonify({'status': 'error', 'message': 'Chyba pri vyp√≠nan√≠ 2FA.'}), 500

@app.route('/api/user/2fa-status')
@login_required
def get_2fa_status():
    """Z√≠skanie stavu 2FA a poƒçtu z√°lo≈æn√Ωch k√≥dov"""
    try:
        with get_db_connection() as conn:
            remaining_codes = conn.execute(
                'SELECT COUNT(*) FROM backup_codes WHERE user_id = ? AND used = 0', 
                (current_user.id,)
            ).fetchone()[0]
        
        return jsonify({
            'totp_enabled': current_user.totp_enabled,
            'remaining_backup_codes': remaining_codes
        })
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ 2FA stavu: {e}")
        return jsonify({'status': 'error', 'message': 'Chyba pri naƒç√≠tavan√≠ stavu.'}), 500

@app.route('/api/devices', methods=['GET', 'POST'])
@login_required
def handle_devices():
    with get_db_connection() as conn:
        if request.method == 'GET':
            # Include all necessary fields including status and last_snmp_data
            devices = []
            for row in conn.execute('SELECT id, name, ip, username, low_memory, snmp_community, snmp_interval_minutes, ping_interval_seconds, ping_retry_interval_seconds, monitoring_paused, status, last_snmp_data, last_backup FROM devices ORDER BY name').fetchall():
                device = dict(row)
                # Convert last_backup to ISO format with UTC timezone for consistent parsing across browsers
                if device.get('last_backup'):
                    try:
                        # SQLite CURRENT_TIMESTAMP returns UTC time in format '2026-02-15 12:22:02'
                        dt = datetime.fromisoformat(device['last_backup'].replace(' ', 'T'))
                        # Mark as UTC by adding timezone info
                        device['last_backup'] = dt.replace(tzinfo=timezone.utc).isoformat()
                    except:
                        pass  # Keep original value if conversion fails
                devices.append(device)
            return jsonify(devices)
        if request.method == 'POST':
            data = request.json
            try:
                if data.get('id'):
                    # Z√≠skame star√© nastavenia pre detekciu zmien intervalov
                    old_device = conn.execute('SELECT snmp_interval_minutes, ping_interval_seconds, ping_retry_interval_seconds FROM devices WHERE id = ?', (data['id'],)).fetchone()
                    old_snmp_interval = old_device['snmp_interval_minutes'] if old_device else 0
                    old_ping_interval = old_device['ping_interval_seconds'] if old_device else 0
                    old_ping_retry_interval = old_device['ping_retry_interval_seconds'] if old_device else 0
                    new_snmp_interval = data.get('snmp_interval_minutes', 0)
                    new_ping_interval = data.get('ping_interval_seconds', 0)
                    new_ping_retry_interval = data.get('ping_retry_interval_seconds', 0)
                    
                    # Pri edit√°cii zachov√°me p√¥vodn√© heslo ak nie je zadan√© nov√©
                    if data.get('password'):
                        # Ak je zadan√© nov√© heslo, aktualizujeme v≈°etko vr√°tane hesla
                        encrypted_password = encrypt_password(data['password'])
                        conn.execute("UPDATE devices SET name=?, ip=?, username=?, password=?, low_memory=?, snmp_community=?, snmp_interval_minutes=?, ping_interval_seconds=?, ping_retry_interval_seconds=? WHERE id=?", 
                                   (data['name'], data['ip'], data['username'], encrypted_password, data.get('low_memory', False), 
                                    data.get('snmp_community', 'public'), new_snmp_interval, 
                                    new_ping_interval, new_ping_retry_interval, data['id']))
                    else:
                        # Ak heslo nie je zadan√©, aktualizujeme len ostatn√© polia
                        conn.execute("UPDATE devices SET name=?, ip=?, username=?, low_memory=?, snmp_community=?, snmp_interval_minutes=?, ping_interval_seconds=?, ping_retry_interval_seconds=? WHERE id=?", 
                                   (data['name'], data['ip'], data['username'], data.get('low_memory', False), 
                                    data.get('snmp_community', 'public'), new_snmp_interval, 
                                    new_ping_interval, new_ping_retry_interval, data['id']))
                    conn.commit()
                    
                    change_messages = []
                    # Okam≈æit√Ω health check ak sa zmenil SNMP interval zariadenia
                    if old_snmp_interval != new_snmp_interval:
                        device_name = data.get('name', f'ID {data["id"]}')
                        trigger_immediate_health_check(f"zmena SNMP intervalu zariadenia {device_name} ({old_snmp_interval}‚Üí{new_snmp_interval}min)")
                        change_messages.append(f"SNMP interval {old_snmp_interval}‚Üí{new_snmp_interval} min (spusten√Ω health check)")
                    if old_ping_interval != new_ping_interval:
                        change_messages.append(f"Ping interval {old_ping_interval}‚Üí{new_ping_interval} s")
                    if old_ping_retry_interval != new_ping_retry_interval:
                        change_messages.append(f"Retry interval {old_ping_retry_interval}‚Üí{new_ping_retry_interval} s")

                    if change_messages:
                        add_log('info', f"Zariadenie {data['ip']} aktualizovan√©: " + ", ".join(change_messages))
                    
                    return jsonify({'status': 'success'})
                else:
                    cursor = conn.cursor()
                    encrypted_password = encrypt_password(data['password'])
                    cursor.execute("INSERT INTO devices (name, ip, username, password, low_memory, snmp_community, snmp_interval_minutes, ping_interval_seconds, ping_retry_interval_seconds) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)", 
                                 (data['name'], data['ip'], data['username'], encrypted_password, data.get('low_memory', False), 
                                  data.get('snmp_community', 'public'), data.get('snmp_interval_minutes', 0), 
                                  data.get('ping_interval_seconds', 0), data.get('ping_retry_interval_seconds', 0)))
                    device_id = cursor.lastrowid
                    conn.commit()
                    add_log('info', f"Zariadenie {data['ip']} pridan√©.")
                    return jsonify({'status': 'success', 'device_id': device_id})
            except sqlite3.IntegrityError: return jsonify({'status': 'error', 'message': 'Zariadenie s touto IP u≈æ existuje'}), 409

@app.route('/api/devices/<int:device_id>', methods=['DELETE'])
@login_required
def delete_device(device_id):
    with get_db_connection() as conn:
        conn.execute("DELETE FROM devices WHERE id = ?", (device_id,))
        conn.commit()
    add_log('warning', f"Zariadenie bolo odstr√°nen√©.")
    return jsonify({'status': 'success'})

@app.route('/api/backup/<int:device_id>', methods=['POST'])
@login_required
def backup_device(device_id):
    with get_db_connection() as conn:
        device = conn.execute('SELECT * FROM devices WHERE id = ?', (device_id,)).fetchone()
    if not device: return jsonify({'status': 'error', 'message': 'Zariadenie nebolo n√°jden√©.'}), 404
    if device['ip'] in backup_tasks: return jsonify({'status': 'error', 'message': 'Z√°loha u≈æ prebieha.'}), 409
    backup_tasks[device['ip']] = True
    threading.Thread(target=run_backup_logic, args=(dict(device), False)).start()  # False = nie je sekvenƒçn√°
    return jsonify({'status': 'success', 'message': 'Z√°loha spusten√°.'})

@app.route('/api/backup/all', methods=['POST'])
@login_required
def backup_all_devices():
    with get_db_connection() as conn:
        devices = [dict(row) for row in conn.execute('SELECT * FROM devices ORDER BY name').fetchall()]
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
    
    # Z√≠skame nastavenie oneskorenia medzi z√°lohami (predvolen√© 30 sek√∫nd)
    backup_delay = int(settings.get('backup_delay_seconds', 30))
    
    # Filtrujeme len zariadenia, ktor√© nemaj√∫ be≈æiacu z√°lohu
    available_devices = [device for device in devices if device['ip'] not in backup_tasks]
    
    if not available_devices:
        return jsonify({'status': 'error', 'message': 'V≈°etky zariadenia u≈æ maj√∫ be≈æiacu z√°lohu alebo nie s√∫ dostupn√© zariadenia.'})
    
    total_devices = len(available_devices)
    add_log('info', f"Sp√∫≈°≈•am sekvenƒçn√∫ hromadn√∫ z√°lohu pre {total_devices} zariaden√≠ s odstupom {backup_delay}s.")
    
    # Spust√≠me sekvenƒçn√∫ z√°lohu v samostatnom vl√°kne
    threading.Thread(target=run_sequential_backup, args=(available_devices, backup_delay)).start()
    
    return jsonify({
        'status': 'success', 
        'message': f'Sekvenƒçn√° hromadn√° z√°loha spusten√° pre {total_devices} zariaden√≠.',
        'total_devices': total_devices
    })

def run_sequential_backup(devices, delay_seconds):
    """Sp√∫≈°≈•a z√°lohy postupne s oneskoren√≠m medzi nimi"""
    global sequential_backup_running, sequential_backup_total, sequential_backup_current
    sequential_backup_running = True
    sequential_backup_total = len(devices)
    sequential_backup_current = 0
    device_results = []
    stopped_early = False
    
    try:
        total_devices = len(devices)
        for i, device in enumerate(devices, 1):
            # Kontrola, ƒçi m√° pou≈æ√≠vateƒæ zastavi≈• sekvenƒçn√∫ z√°lohu
            if not sequential_backup_running:
                add_log('warning', "Sekvenƒçn√° z√°loha bola zastaven√° pou≈æ√≠vateƒæom.")
                stopped_early = True
                break

            sequential_backup_current = i
            ip = device['ip']
            if ip in backup_tasks:
                add_log('warning', "Z√°loha u≈æ prebieha, preskakujem.", ip)
                continue
            
            add_log('info', f"Sp√∫≈°≈•am z√°lohu {i}/{total_devices}...", ip)
            backup_tasks[ip] = True
            
            # Spust√≠me z√°lohu s pr√≠znakom sekvenƒçnej z√°lohy a poƒçk√°me na jej dokonƒçenie
            result_holder = {'backup_performed': False, 'ftp_uploaded': False}
            backup_thread = threading.Thread(target=run_backup_logic, args=(device, True, result_holder))  # True = is_sequential
            backup_thread.start()
            backup_thread.join()  # Poƒçk√°me k√Ωm sa z√°loha dokonƒç√≠
            device_results.append(result_holder)
            
            # Ak nie je posledn√© zariadenie, poƒçk√°me pred ƒèal≈°ou z√°lohou
            if i < total_devices and sequential_backup_running:
                add_log('info', f"ƒåak√°m {delay_seconds} sek√∫nd pred ƒèal≈°ou z√°lohou...")
                for _ in range(delay_seconds):
                    if not sequential_backup_running:
                        break
                    time.sleep(1)
    finally:
        sequential_backup_running = False
        sequential_backup_current = 0
        sequential_backup_total = 0
        if device_results and not stopped_early:
            performed = [res for res in device_results if res.get('backup_performed')]
            if performed:
                if all(res.get('ftp_uploaded') for res in performed):
                    add_log('info', "V≈°etky vytvoren√© z√°lohy boli √∫spe≈°ne nahrat√© na FTP server.")
                else:
                    add_log('warning', "Niektor√© vytvoren√© z√°lohy sa nepodarilo nahra≈• na FTP server. Skontrolujte logy zariaden√≠.")
        add_log('info', "Sekvenƒçn√° z√°loha dokonƒçen√°.")

@app.route('/api/snmp/<int:device_id>', methods=['GET'])
@login_required
def check_snmp(device_id):
    result = perform_snmp_poll(device_id, reason="manual")

    # Zvl√°dnutie stavov podƒæa v√Ωsledku
    if result.get('status') == 'missing':
        return jsonify({'status': 'error', 'message': 'Zariadenie nen√°jden√©'}), 404
    if result.get('error'):
        return jsonify({'status': 'error', 'message': result['error']}), 500

    device = result.get('device')
    if not device:
        with get_db_connection() as conn:
            device = conn.execute(
                'SELECT id, snmp_interval_minutes FROM devices WHERE id = ?',
                (device_id,)
            ).fetchone()
            if not device:
                return jsonify({'status': 'error', 'message': 'Zariadenie nen√°jden√©'}), 404
    
    with get_db_connection() as conn:
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
        global_interval = int(settings.get('snmp_check_interval_minutes', 10))
    
    # Urƒç√≠ interval pre toto zariadenie
    try:
        snmp_interval_value = device['snmp_interval_minutes']
    except (KeyError, TypeError):
        if isinstance(device, (tuple, list)) and len(device) > 1:
            snmp_interval_value = device[1]
        else:
            snmp_interval_value = 0
    device_interval = snmp_interval_value if snmp_interval_value and snmp_interval_value > 0 else global_interval
    
    # Re≈°tartuj timer s immediate=True pre okam≈æit√© nastavenie ƒèal≈°ieho checku
    restart_snmp_timer_for_device(device_id, device_interval)
    
    snmp_data = result.get('snmp_data') or {}
    return jsonify(snmp_data)

@app.route('/api/snmp/refresh-all', methods=['POST'])
@login_required
def snmp_refresh_all_devices():
    """Spust√≠ sekvenƒçn√Ω refresh SNMP d√°t pre v≈°etky zariadenia"""
    global sequential_snmp_refresh_running
    
    # Skontrolujeme ƒçi u≈æ prebieha refresh
    if sequential_snmp_refresh_running:
        return jsonify({'status': 'error', 'message': 'SNMP refresh v≈°etk√Ωch zariaden√≠ u≈æ prebieha.'}), 409
    
    with get_db_connection() as conn:
        devices = [dict(row) for row in conn.execute('SELECT id, ip, name, snmp_community FROM devices ORDER BY name').fetchall()]
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
    
    # Z√≠skame nastavenie oneskorenia medzi refresh-mi (predvolen√© 0.5 sek√∫nd)
    refresh_delay = float(settings.get('snmp_refresh_delay_seconds', 0.5))
    
    if not devices:
        return jsonify({'status': 'error', 'message': '≈Ωiadne zariadenia nie s√∫ dostupn√©.'})
    
    # Log odstr√°nen√Ω - zbytoƒçne zahlt√°va aktivitu logov
    
    # Spust√≠me sekvenƒçn√Ω refresh v samostatnom vl√°kne
    threading.Thread(target=run_sequential_snmp_refresh, args=(devices, refresh_delay)).start()
    
    return jsonify({
        'status': 'success', 
        'message': f'Hromadn√Ω SNMP refresh spusten√Ω pre {len(devices)} zariaden√≠.',
        'total_devices': len(devices)
    })

def run_sequential_snmp_refresh(devices, delay_seconds):
    """Sp√∫≈°≈•a SNMP refresh postupne s oneskoren√≠m medzi nimi"""
    global sequential_snmp_refresh_running, snmp_refresh_progress
    sequential_snmp_refresh_running = True
    
    total_devices = len(devices)
    snmp_refresh_progress = {'current': 0, 'total': total_devices}
    
    # Odo≈°leme poƒçiatoƒçn√Ω stav cez WebSocket
    socketio.emit('snmp_refresh_progress', {
        'status': 'started',
        'current': 0,
        'total': total_devices,
        'message': f'Zaƒç√≠nam refresh pre {total_devices} zariaden√≠'
    })
    
    try:
        for i, device in enumerate(devices, 1):
            # Kontrola, ƒçi m√° pou≈æ√≠vateƒæ zastavi≈• sekvenƒçn√Ω refresh
            if not sequential_snmp_refresh_running:
                add_log('warning', "Hromadn√Ω SNMP refresh bol zastaven√Ω pou≈æ√≠vateƒæom.")
                break
            
            device_id = device['id']
            ip = device['ip']
            snmp_community = device['snmp_community']
            
            # Aktualizujeme progress
            snmp_refresh_progress['current'] = i
            
            # Odo≈°leme progress update cez WebSocket
            socketio.emit('snmp_refresh_progress', {
                'status': 'processing',
                'current': i,
                'total': total_devices,
                'current_device': {'id': device_id, 'ip': ip, 'name': device['name']},
                'message': f'Refresh {i}/{total_devices}: {device["name"]} ({ip})'
            })
            
            # Log odstr√°nen√Ω - zbytoƒçne zahlt√°va aktivitu logov
            
            try:
                # Spust√≠me SNMP refresh pre aktu√°lne zariadenie
                snmp_data = get_snmp_data(ip, snmp_community)
                status = 'online' if snmp_data.get('uptime') != 'N/A' else 'offline'
                current_time = datetime.now()
                
                # Ulo≈æ√≠me do datab√°zy
                with get_db_connection() as conn:
                    conn.execute("UPDATE devices SET last_snmp_data = ?, status = ?, last_snmp_check = ? WHERE id = ?", 
                               (json.dumps(snmp_data), status, current_time.isoformat(), device_id))
                    conn.commit()
                
                # Ulo≈æenie do SNMP hist√≥rie
                save_snmp_history(device_id, snmp_data)
                
                # Odo≈°leme update pre konkr√©tne zariadenie
                socketio.emit('snmp_update', {'id': device_id, 'data': snmp_data, 'status': status})
                
            except Exception as e:
                add_log('error', f"Chyba pri SNMP refresh pre {device['name']} ({ip}): {str(e)}", ip)
                # Pokraƒçujeme s ƒèal≈°√≠m zariaden√≠m aj pri chybe
            
            # Ak nie je posledn√© zariadenie, poƒçk√°me pred ƒèal≈°√≠m refresh-om
            if i < total_devices and sequential_snmp_refresh_running and delay_seconds > 0:
                time.sleep(delay_seconds)
        
        # Dokonƒçenie
        if sequential_snmp_refresh_running:  # Ak nebol zastaven√Ω pou≈æ√≠vateƒæom
            # Log odstr√°nen√Ω - zbytoƒçne zahlt√°va aktivitu logov
            socketio.emit('snmp_refresh_progress', {
                'status': 'completed',
                'current': snmp_refresh_progress['current'],
                'total': total_devices,
                'message': f'Refresh dokonƒçen√Ω: {snmp_refresh_progress["current"]}/{total_devices} zariaden√≠'
            })
        
    except Exception as e:
        add_log('error', f"Kritick√° chyba pri hromadnom SNMP refresh: {str(e)}")
        socketio.emit('snmp_refresh_progress', {
            'status': 'error',
            'current': snmp_refresh_progress['current'],
            'total': total_devices,
            'message': f'Chyba pri refresh: {str(e)}'
        })
    finally:
        sequential_snmp_refresh_running = False
        snmp_refresh_progress = {'current': 0, 'total': 0}

@app.route('/api/snmp/refresh-all/status', methods=['GET'])
@login_required
def snmp_refresh_all_status():
    """Vr√°ti aktu√°lny stav hromadn√©ho SNMP refresh"""
    return jsonify({
        'is_running': sequential_snmp_refresh_running,
        'progress': snmp_refresh_progress
    })

@app.route('/api/snmp/refresh-all/stop', methods=['POST'])
@login_required
def stop_snmp_refresh_all():
    """Zastav√≠ hromadn√Ω SNMP refresh"""
    global sequential_snmp_refresh_running
    
    if not sequential_snmp_refresh_running:
        return jsonify({'status': 'error', 'message': '≈Ωiadny hromadn√Ω SNMP refresh neprebieha.'})
    
    sequential_snmp_refresh_running = False
    add_log('warning', "Hromadn√Ω SNMP refresh bol zastaven√Ω pou≈æ√≠vateƒæom.")
    
    socketio.emit('snmp_refresh_progress', {
        'status': 'stopped',
        'current': snmp_refresh_progress['current'],
        'total': snmp_refresh_progress['total'],
        'message': 'Refresh bol zastaven√Ω pou≈æ√≠vateƒæom'
    })
    
    return jsonify({
        'status': 'success',
        'message': 'Hromadn√Ω SNMP refresh bol zastaven√Ω.'
    })

@app.route('/api/settings', methods=['GET', 'POST'])
@login_required
def handle_settings():
    with get_db_connection() as conn:
        if request.method == 'GET': return jsonify({row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()})
        if request.method == 'POST':
            # Valid√°cia ping_check_interval_seconds
            ping_interval = request.json.get('ping_check_interval_seconds')
            if ping_interval is not None:
                try:
                    ping_interval_int = int(ping_interval)
                    if ping_interval_int < 20 or ping_interval_int > 86400:
                        return jsonify({'status': 'error', 'message': 'Glob√°lny ping interval mus√≠ by≈• 20-86400 sek√∫nd'}), 400
                except (ValueError, TypeError):
                    return jsonify({'status': 'error', 'message': 'Neplatn√° hodnota pre ping interval'}), 400

            # Valid√°cia intervalu SNMP health checku
            health_interval = request.json.get('snmp_health_check_interval_minutes')
            if health_interval is not None:
                try:
                    health_interval_int = int(health_interval)
                    if health_interval_int < 1 or health_interval_int > 1440:
                        return jsonify({'status': 'error', 'message': 'SNMP health check interval mus√≠ by≈• 1-1440 min√∫t'}), 400
                except (ValueError, TypeError):
                    return jsonify({'status': 'error', 'message': 'Neplatn√° hodnota pre SNMP health check interval'}), 400
            
            # Naƒç√≠tame p√¥vodn√© nastavenia pre porovnanie zmien
            old_settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}

            def normalize_setting_value(key, value):
                if value is None:
                    return ''
                value_str = str(value)
                if key in BOOLEAN_SETTING_KEYS:
                    return value_str.lower()
                return value_str

            def old_value(key):
                stored = old_settings.get(key)
                if stored is None or stored == '':
                    stored = DEFAULT_SETTING_VALUES.get(key, '')
                return normalize_setting_value(key, stored)

            def request_value(key):
                return normalize_setting_value(key, request.json.get(key))

            def setting_changed(key):
                if key not in request.json:
                    return False
                return request_value(key) != old_value(key)

            def new_value(key):
                return request_value(key) if key in request.json else old_value(key)
            
            for key, value in request.json.items():
                conn.execute("INSERT OR REPLACE INTO settings (key, value) VALUES (?, ?)", (key, str(value)))
            conn.commit()
            add_log('info', "Glob√°lne nastavenia ulo≈æen√© pou≈æ√≠vateƒæom.")
            
            changed_keys = sorted(key for key in request.json.keys() if setting_changed(key))
            for key in changed_keys:
                label = get_setting_label(key)
                if key in SENSITIVE_SETTINGS:
                    add_log('info', f"{label} bolo aktualizovan√© (hodnota je skryt√°).")
                else:
                    previous_value = format_setting_value(key, old_value(key))
                    current_value = format_setting_value(key, new_value(key))
                    add_log('info', f"{label} zmenen√© z {previous_value} na {current_value}.")
            
            # Kontrola ƒçi sa zmenili ping nastavenia
            ping_settings_changed = setting_changed('ping_check_interval_seconds') or setting_changed('ping_monitor_enabled')
            
            # Kontrola ƒçi sa zmenili SNMP nastavenia
            snmp_interval_changed = setting_changed('snmp_check_interval_minutes')
            snmp_health_changed = setting_changed('snmp_health_check_enabled') or setting_changed('snmp_health_check_interval_minutes')
            backup_schedule_keys = ('backup_schedule_enabled', 'backup_schedule_type', 'backup_schedule_day', 'backup_schedule_time')
            backup_schedule_changed = any(setting_changed(key) for key in backup_schedule_keys)
            
            if ping_settings_changed:
                restart_ping_monitoring()
                add_log('info', f"Ping monitoring re≈°tartovan√Ω s nov√Ωmi nastaveniami: interval {new_value('ping_check_interval_seconds')}s, povolen√Ω: {new_value('ping_monitor_enabled')}")
            
            if snmp_interval_changed:
                stop_all_snmp_timers()
                start_all_snmp_timers()
                # Okam≈æit√Ω health check po zmene intervalu pre zabezpeƒçenie spr√°vneho fungovania
                trigger_immediate_health_check("glob√°lna zmena SNMP intervalu")
                add_log('info', f"SNMP timery re≈°tartovan√© s nov√Ωm glob√°lnym intervalom: {new_value('snmp_check_interval_minutes')} min√∫t")

            if snmp_health_changed:
                details = []
                if setting_changed('snmp_health_check_enabled'):
                    is_enabled = new_value('snmp_health_check_enabled') == 'true'
                    details.append(f"stav: {'zapnut√Ω' if is_enabled else 'vypnut√Ω'}")
                if setting_changed('snmp_health_check_interval_minutes'):
                    details.append(f"interval: {new_value('snmp_health_check_interval_minutes')} min√∫t")
                detail_text = f" ({', '.join(details)})" if details else ""
                add_log('info', f"SNMP health check nastavenia aktualizovan√©{detail_text}.")
            
            backup_general_changes = []
            if setting_changed('backup_delay_seconds'):
                backup_general_changes.append(f"oneskorenie medzi z√°lohami: {new_value('backup_delay_seconds')}s")
            if setting_changed('backup_retention_count'):
                backup_general_changes.append(f"retencia z√°loh: {new_value('backup_retention_count')} ks")
            if setting_changed('backup_detailed_logging'):
                backup_general_changes.append(f"detailn√© logovanie: {'zapnut√©' if new_value('backup_detailed_logging') == 'true' else 'vypnut√©'}")
            if backup_general_changes:
                add_log('info', f"Automatick√© z√°lohovanie ‚Äî upraven√© nastavenia ({'; '.join(backup_general_changes)}).")
            
            # Znovu nastav√≠me scheduler bez logovania
            setup_scheduler(log_schedule_info=False)
            
            # Prid√°me info o pl√°ne len ak sa zmenilo nastavenie automatick√Ωch z√°loh
            if backup_schedule_changed:
                schedule_info = get_schedule_info()
                if schedule_info:
                    add_log('info', schedule_info)
            
            return jsonify({
                'status': 'success'
            })

@app.route('/api/notifications/test', methods=['POST'])
@login_required
def test_notification():
    send_pushover_notification("üîî Toto je testovacia spr√°va z MikroTik Manager.")
    return jsonify({'status': 'success'})

@app.route('/api/snmp/timers/status', methods=['GET'])
@login_required
def get_snmp_timers_status():
    """Diagnostika stavu SNMP timerov"""
    try:
        with get_db_connection() as conn:
            devices = conn.execute('SELECT id, name, ip, snmp_interval_minutes, last_snmp_check, monitoring_paused FROM devices').fetchall()
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            global_interval = int(settings.get('snmp_check_interval_minutes', 10))

        current_time = datetime.now()
        now_ts = time.time()

        with snmp_task_lock:
            queue_length = len(snmp_task_queue)
            state_snapshot = {device_id: dict(state) for device_id, state in snmp_task_state.items()}

        timer_status = []
        for device in devices:
            device_id = device['id']
            effective_interval = device['snmp_interval_minutes'] if device['snmp_interval_minutes'] and device['snmp_interval_minutes'] > 0 else global_interval
            effective_interval = max(effective_interval, 1)

            state = state_snapshot.get(device_id)
            next_run_minutes = None
            running = False
            paused_state = False

            if state:
                paused_state = state.get('paused', False)
                running = state.get('running', False)
                next_run = state.get('next_run')
                if next_run:
                    next_run_minutes = round(max(0.0, (next_run - now_ts) / 60), 2)

            last_check_minutes = None
            if device['last_snmp_check']:
                try:
                    last_check = datetime.fromisoformat(device['last_snmp_check'])
                    last_check_minutes = (current_time - last_check).total_seconds() / 60
                except Exception as e:
                    logger.error(f"Error parsing last_snmp_check for device {device_id}: {e}")

            if device['monitoring_paused']:
                status = 'paused'
            elif not state:
                status = 'missing'
            elif paused_state:
                status = 'paused'
            elif running:
                status = 'running'
            elif last_check_minutes and last_check_minutes > effective_interval * 2:
                status = 'overdue'
            else:
                status = 'scheduled'

            timer_status.append({
                'device_id': device_id,
                'device_name': device['name'],
                'device_ip': device['ip'],
                'interval_minutes': effective_interval,
                'status': status,
                'monitoring_paused': bool(device['monitoring_paused']),
                'next_run_minutes': next_run_minutes,
                'last_check_minutes_ago': round(last_check_minutes, 1) if last_check_minutes is not None else None,
                'running': running
            })

        return jsonify({
            'queue_length': queue_length,
            'tracked_devices': len(state_snapshot),
            'devices': timer_status
        })
    except Exception as e:
        logger.error(f"Error getting SNMP timer status: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/snmp/timers/restart-all', methods=['POST'])
@login_required
def restart_all_snmp_timers():
    """Re≈°tartuje v≈°etky SNMP timery s CPU optimaliz√°ciou"""
    try:
        logger.info("Restarting all SNMP timers with CPU optimization...")
        stop_all_snmp_timers()
        # Kr√°tka pauza pred spusten√≠m nov√Ωch timerov
        time.sleep(2)
        start_all_snmp_timers()
        add_log('info', "V≈°etky SNMP timery boli manu√°lne re≈°tartovan√© s postupn√Ωm sp√∫≈°≈•an√≠m")
        logger.info("All SNMP timers restarted with staggered start delays")
        return jsonify({'status': 'success', 'message': 'V≈°etky SNMP timery re≈°tartovan√© s CPU optimaliz√°ciou'})
    except Exception as e:
        logger.error(f"Error restarting all SNMP timers: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/snmp/timers/health-check', methods=['POST'])
@login_required
def manual_health_check():
    """Manu√°lna kontrola zdravia timerov"""
    try:
        data = request.get_json() or {}
        reason = data.get('reason', 'manu√°lne spustenie z UI')
        
        if trigger_immediate_health_check(reason):
            add_log('info', f"Manu√°lna kontrola zdravia SNMP timerov spusten√° - d√¥vod: {reason}")
            return jsonify({'status': 'success', 'message': 'Health check spusten√Ω'})
        else:
            return jsonify({'status': 'throttled', 'message': 'Health check bol throttled (spusten√Ω ned√°vno)'})
    except Exception as e:
        logger.error(f"Error in manual health check: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/logs', methods=['GET'])
@login_required
def get_logs():
    try:
        with get_db_connection() as conn:
            # Z√≠skame nastavenie pre limit zobrazen√Ωch logov
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            log_limit = int(settings.get('log_max_entries', 2000))
            
            # Vraciame posledn√Ωch X z√°znamov, najnov≈°ie prv√©
            logs = conn.execute('SELECT * FROM logs ORDER BY timestamp DESC LIMIT ?', (log_limit,)).fetchall()
            return jsonify([dict(row) for row in logs])
    except Exception as e:
        logger.error(f"Chyba pri naƒç√≠tan√≠ logov: {e}")
        return jsonify({'status': 'error', 'message': 'Chyba pri naƒç√≠tan√≠ logov'}), 500

@app.route('/api/logs/export', methods=['GET'])
@login_required
def export_logs():
    """Exportuje v≈°etky logy do CSV s√∫boru"""
    try:
        import csv
        from io import StringIO
        
        with get_db_connection() as conn:
            # Exportujeme v≈°etky logy, najnov≈°ie prv√©
            logs = conn.execute('SELECT timestamp, level, message, device_ip FROM logs ORDER BY timestamp DESC').fetchall()
        
        # Vytvor√≠me CSV v pam√§ti
        output = StringIO()
        writer = csv.writer(output)
        
        # Hlaviƒçka CSV
        writer.writerow(['D√°tum a ƒças', '√örove≈à', 'Spr√°va', 'IP zariadenia'])
        
        # D√°ta
        for log in logs:
            timestamp = log[0]
            level = log[1]
            message = log[2]
            device_ip = log[3] or ''
            
            # Form√°tujeme timestamp pre export
            try:
                if isinstance(timestamp, str):
                    dt = datetime.fromisoformat(timestamp)
                else:
                    dt = timestamp
                formatted_timestamp = dt.strftime('%Y-%m-%d %H:%M:%S')
            except:
                formatted_timestamp = str(timestamp)
            
            writer.writerow([formatted_timestamp, level, message, device_ip])
        
        # Priprav√≠me response
        csv_content = output.getvalue()
        output.close()
        
        response = app.response_class(
            csv_content,
            mimetype='text/csv',
            headers={
                'Content-Disposition': f'attachment; filename=mikrotik_logy_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
            }
        )
        
        add_log('info', "Logy boli exportovan√© do CSV s√∫boru.")
        return response
        
    except Exception as e:
        logger.error(f"Chyba pri exporte logov: {e}")
        return jsonify({'status': 'error', 'message': 'Chyba pri exporte logov'}), 500

@app.route('/api/logs/cleanup', methods=['POST'])
@login_required
def cleanup_logs():
    """Vyƒçist√≠ star√© logy podƒæa nastavenia"""
    try:
        with get_db_connection() as conn:
            # Z√≠skame nastavenie pre uchov√°vanie logov
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            retention_days = int(settings.get('log_retention_days', 30))
            
            # Zmazanie logov star≈°√≠ch ako nastaven√Ω poƒçet dn√≠
            cutoff_date = datetime.now() - timedelta(days=retention_days)
            result = conn.execute('DELETE FROM logs WHERE timestamp < ?', (cutoff_date,))
            deleted_count = result.rowcount
            conn.commit()
            
        add_log('info', f"Vyƒçisten√© {deleted_count} star√Ωch logov (star≈°√≠ch ako {retention_days} dn√≠)")
        return jsonify({'status': 'success', 'deleted_count': deleted_count, 'retention_days': retention_days})
    except Exception as e:
        logger.error(f"Chyba pri ƒçisten√≠ logov: {e}")
        return jsonify({'status': 'error', 'message': 'Chyba pri ƒçisten√≠ logov'}), 500

@app.route('/api/logs/cleanup-debug', methods=['POST'])
@login_required
def cleanup_debug_logs():
    """Vyƒçist√≠ v≈°etky debug logy"""
    try:
        with get_db_connection() as conn:
            result = conn.execute("DELETE FROM logs WHERE level = 'DEBUG'")
            deleted_count = result.rowcount
            conn.commit()
            
        add_log('info', f"Vyƒçisten√© {deleted_count} debug logov")
        return jsonify({'status': 'success', 'deleted_count': deleted_count})
    except Exception as e:
        logger.error(f"Chyba pri ƒçisten√≠ debug logov: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

def scheduled_backup_job():
    with app.app_context():
        add_log('info', "Sp√∫≈°≈•am napl√°novan√∫ √∫lohu z√°lohovania...")
        # Pou≈æijeme sekvenƒçn√© z√°lohovanie aj pre pl√°novan√© √∫lohy
        with get_db_connection() as conn:
            devices = [dict(row) for row in conn.execute('SELECT * FROM devices').fetchall()]
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
        
        backup_delay = int(settings.get('backup_delay_seconds', 30))
        available_devices = [device for device in devices if device['ip'] not in backup_tasks]
        
        if available_devices:
            add_log('info', f"Pl√°novan√© z√°lohovanie: Sp√∫≈°≈•am sekvenƒçn√∫ z√°lohu pre {len(available_devices)} zariaden√≠.")
            run_sequential_backup(available_devices, backup_delay)
        else:
            add_log('warning', "Pl√°novan√© z√°lohovanie: ≈Ωiadne dostupn√© zariadenia na z√°lohovanie.")

# SNMP Scheduler - centralized management of SNMP polling
SNMP_MAX_WORKERS = int(os.environ.get('SNMP_MAX_WORKERS', '3'))
snmp_executor = ThreadPoolExecutor(max_workers=SNMP_MAX_WORKERS)
snmp_scheduler_thread = None
snmp_scheduler_stop = threading.Event()
snmp_scheduler_wakeup = threading.Event()
snmp_task_queue = []
snmp_task_state = {}
snmp_task_lock = threading.Lock()
snmp_task_counter = itertools.count()

def trigger_immediate_health_check(reason="manu√°lne spustenie"):
    """Spust√≠ okam≈æit√Ω health check s inteligentn√Ωm throttling pre zabr√°nenie nadmern√©ho pou≈æ√≠vania"""
    try:
        # Inteligentn√© throttling: krat≈°ie pre SNMP zmeny, dlh≈°ie pre manu√°lne volania
        current_time = time.time()
        if not hasattr(trigger_immediate_health_check, 'last_run'):
            trigger_immediate_health_check.last_run = 0

        time_since_last = current_time - trigger_immediate_health_check.last_run

        # Inteligentn√© throttling podƒæa d√¥vodu
        if "snmp" in reason.lower() or "interval" in reason.lower():
            # Pre SNMP zmeny: len 5 sek√∫nd throttling (u≈æ√≠vateƒæ m√¥≈æe r√Ωchlo meni≈• nastavenia)
            throttle_time = 5
        else:
            # Pre manu√°lne volania: 30 sek√∫nd throttling (prevencia spam)
            throttle_time = 30

        if time_since_last < throttle_time:
            logger.info(f"Health check throttled - posledn√Ω spusten√Ω pred {time_since_last:.1f}s, potrebn√Ωch {throttle_time}s (d√¥vod: {reason})")
            return False

        def run_health_check():
            try:
                with app.app_context():
                    logger.info(f"Sp√∫≈°≈•am okam≈æit√Ω SNMP health check - d√¥vod: {reason}")
                    check_snmp_timers_health()
                    logger.info("Okam≈æit√Ω SNMP health check dokonƒçen√Ω")
            except Exception as e:
                logger.error(f"Chyba v okam≈æitom health check: {e}")

        health_check_thread = threading.Thread(target=run_health_check, daemon=True)
        health_check_thread.start()

        trigger_immediate_health_check.last_run = current_time
        return True

    except Exception as e:
        logger.error(f"Chyba pri sp√∫≈°≈•an√≠ okam≈æit√©ho health check: {e}")
        return False

def ensure_snmp_scheduler_running():
    """Spust√≠ scheduler thread ak e≈°te nebe≈æ√≠."""
    global snmp_scheduler_thread
    if snmp_scheduler_thread and snmp_scheduler_thread.is_alive():
        return
    snmp_scheduler_stop.clear()
    snmp_scheduler_wakeup.clear()
    snmp_scheduler_thread = threading.Thread(target=snmp_scheduler_loop, daemon=True, name="snmp_scheduler")
    snmp_scheduler_thread.start()
    debug_log('debug_snmp_timers', "SNMP scheduler thread started")

def schedule_snmp_task(device_id, interval_minutes, delay_seconds=0, reason="manual_schedule"):
    """Prid√° alebo aktualizuje SNMP √∫lohu pre zariadenie."""
    ensure_snmp_scheduler_running()
    interval = max(int(interval_minutes), 1)
    delay = max(float(delay_seconds), 0.0)
    next_run = time.time() + delay
    with snmp_task_lock:
        current = snmp_task_state.get(device_id, {})
        version = current.get('version', 0) + 1
        running = current.get('running', False)
        snmp_task_state[device_id] = {
            'interval': interval,
            'paused': False,
            'next_run': next_run,
            'version': version,
            'running': running
        }
        heapq.heappush(snmp_task_queue, (next_run, next(snmp_task_counter), device_id, version))
    snmp_scheduler_wakeup.set()
    debug_log('debug_snmp_timers', f"Scheduled SNMP task for device {device_id} in {delay:.1f}s (interval {interval}min, reason: {reason})")

def pause_snmp_task(device_id, reason="pause"):
    """Pozastav√≠ SNMP √∫lohu pre zariadenie."""
    with snmp_task_lock:
        current = snmp_task_state.get(device_id, {})
        version = current.get('version', 0) + 1
        interval = current.get('interval', 1)
        snmp_task_state[device_id] = {
            'interval': interval,
            'paused': True,
            'next_run': None,
            'version': version,
            'running': False
        }
    snmp_scheduler_wakeup.set()
    debug_log('debug_snmp_timers', f"Paused SNMP task for device {device_id} (reason: {reason})")

def snmp_scheduler_loop():
    """Hlavn√Ω loop scheduleru vyu≈æ√≠vaj√∫ci priority queue."""
    logger.info("SNMP scheduler loop started")
    while not snmp_scheduler_stop.is_set():
        with snmp_task_lock:
            if snmp_task_queue:
                next_run, counter, device_id, version = snmp_task_queue[0]
            else:
                next_run = None

        if next_run is None:
            snmp_scheduler_wakeup.wait(timeout=1.0)
            snmp_scheduler_wakeup.clear()
            continue

        now = time.time()
        wait_time = max(0.0, next_run - now)
        if snmp_scheduler_wakeup.wait(timeout=wait_time):
            snmp_scheduler_wakeup.clear()
            continue

        if snmp_scheduler_stop.is_set():
            break

        with snmp_task_lock:
            if not snmp_task_queue:
                continue
            due_time, counter, device_id, version = heapq.heappop(snmp_task_queue)
            state = snmp_task_state.get(device_id)
            if not state:
                continue
            if state.get('version') != version or state.get('paused'):
                state['running'] = False
                continue
            now = time.time()
            if due_time > now:
                heapq.heappush(snmp_task_queue, (due_time, counter, device_id, version))
                continue
            if state.get('running'):
                reschedule_time = now + 1.0
                state['next_run'] = reschedule_time
                heapq.heappush(snmp_task_queue, (reschedule_time, next(snmp_task_counter), device_id, version))
                continue
            state['running'] = True
            state['next_run'] = now

        snmp_executor.submit(run_snmp_job, device_id, version)

    logger.info("SNMP scheduler loop stopped")

def mark_snmp_task_complete(device_id, version):
    """Oznaƒç√≠ √∫lohu ako dokonƒçen√∫ a napl√°nuje ƒèal≈°√≠ interval."""
    with snmp_task_lock:
        state = snmp_task_state.get(device_id)
        if not state:
            return
        state['running'] = False
        if state.get('version') != version or state.get('paused'):
            return
        interval = max(state.get('interval', 1), 1)
        next_run = time.time() + interval * 60
        state['next_run'] = next_run
        heapq.heappush(snmp_task_queue, (next_run, next(snmp_task_counter), device_id, version))
    snmp_scheduler_wakeup.set()

def perform_snmp_poll(device_id, reason="scheduler"):
    """Vykon√° SNMP dotaz pre zariadenie vr√°tane ulo≈æenia d√°t a notifik√°ci√≠."""
    try:
        with get_db_connection() as conn:
            device = conn.execute(
                'SELECT id, name, ip, snmp_community, monitoring_paused, last_snmp_data, snmp_interval_minutes FROM devices WHERE id = ?',
                (device_id,)
            ).fetchone()

        if not device:
            logger.warning(f"SNMP poll skipped - device {device_id} not found (reason: {reason})")
            with snmp_task_lock:
                snmp_task_state.pop(device_id, None)
            return {'status': 'missing', 'snmp_data': None, 'device': None}

        if device['monitoring_paused'] and reason != "manual":
            debug_log('debug_snmp_timers', f"SNMP poll skipped - device {device['name']} monitoring paused (reason: {reason})")
            return {'status': 'paused', 'snmp_data': None, 'device': device}

        previous_data = {}
        if device['last_snmp_data']:
            try:
                previous_data = json.loads(device['last_snmp_data'])
            except Exception as decode_error:
                debug_log('debug_snmp_data', f"Nepodarilo sa dek√≥dova≈• predch√°dzaj√∫ce SNMP d√°ta ({device['name']}): {decode_error}")
                previous_data = {}

        snmp_data = get_snmp_data(device['ip'], device['snmp_community'])
        has_valid_metrics = snmp_data.get('uptime') != 'N/A'
        status = 'online' if has_valid_metrics else 'offline'
        timestamp = datetime.now()

        with get_db_connection() as conn:
            if has_valid_metrics:
                conn.execute(
                    "UPDATE devices SET last_snmp_data = ?, status = ?, last_snmp_check = ? WHERE id = ?",
                    (json.dumps(snmp_data), status, timestamp.isoformat(), device_id)
                )
            else:
                conn.execute(
                    "UPDATE devices SET status = ?, last_snmp_check = ? WHERE id = ?",
                    (status, timestamp.isoformat(), device_id)
                )
            conn.commit()

        save_snmp_history(device_id, snmp_data)
        debug_emit('snmp_update', {'id': device_id, 'data': snmp_data, 'status': status})

        if has_valid_metrics:
            evaluate_snmp_notifications(
                device,
                snmp_data,
                previous_data if previous_data.get('uptime') != 'N/A' else {}
            )
            debug_log('debug_snmp_data', f"SNMP data saved for {device['name']} (reason: {reason})")
        else:
            logger.warning(f"SNMP d√°ta pre {device['name']} neobsahovali platn√Ω uptime (reason: {reason})")

        return {
            'status': status,
            'snmp_data': snmp_data,
            'device': device,
            'has_valid': has_valid_metrics,
            'previous_data': previous_data
        }
    except Exception as e:
        logger.error(f"Error during SNMP poll for device {device_id}: {e}")
        device_ip = None
        try:
            device_ip = device['ip']  # type: ignore[name-defined]
        except Exception:
            device_ip = None
        add_log('error', f"SNMP query for device {device_id} failed: {e}", device_ip=device_ip)
        return {'status': 'error', 'error': str(e), 'snmp_data': None, 'device': None}

def run_snmp_job(device_id, version):
    """Worker funkcia vykonan√° vo thread poole."""
    try:
        with app.app_context():
            perform_snmp_poll(device_id, reason="scheduler")
    finally:
        mark_snmp_task_complete(device_id, version)

def trigger_immediate_snmp_check_for_device(device_id, reason="ping_observed_online"):
    """Spust√≠ okam≈æit√Ω SNMP check pre jedno zariadenie a re≈°tartuje jeho timer."""
    try:
        with get_db_connection() as conn:
            device = conn.execute(
                'SELECT name, ip, snmp_interval_minutes, monitoring_paused FROM devices WHERE id = ?',
                (device_id,)
            ).fetchone()
            if not device:
                logger.warning(f"Immediate SNMP trigger skipped - device {device_id} not found (reason: {reason})")
                return False
            settings = {
                row['key']: row['value']
                for row in conn.execute(
                    'SELECT key, value FROM settings WHERE key = ?',
                    ('snmp_check_interval_minutes',)
                ).fetchall()
            }
        if device['monitoring_paused']:
            debug_log('debug_snmp_timers', f"Immediate SNMP trigger skipped - device {device['name']} is paused")
            return False
        global_interval = int(settings.get('snmp_check_interval_minutes', 10))
        interval_minutes = device['snmp_interval_minutes'] if device['snmp_interval_minutes'] and device['snmp_interval_minutes'] > 0 else global_interval
        schedule_snmp_task(device_id, interval_minutes, delay_seconds=0, reason=reason)
        return True
    except Exception as e:
        logger.error(f"Failed to trigger immediate SNMP check for device {device_id} ({reason}): {e}")
        return False

def check_snmp_timers_health():
    """Kontroluje zdravie SNMP √∫loh a re≈°tartuje ch√Ωbaj√∫ce alebo zaseknut√©."""
    try:
        with get_db_connection() as conn:
            devices = conn.execute('SELECT id, name, ip, snmp_interval_minutes, last_snmp_check, monitoring_paused FROM devices').fetchall()
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            global_interval = int(settings.get('snmp_check_interval_minutes', 10))
        ensure_snmp_scheduler_running()
        recovered = 0
        current_time = datetime.now()
        for device in devices:
            device_id = device['id']
            paused_db = bool(device['monitoring_paused'])
            effective_interval = device['snmp_interval_minutes'] if device['snmp_interval_minutes'] and device['snmp_interval_minutes'] > 0 else global_interval
            effective_interval = max(effective_interval, 1)
            with snmp_task_lock:
                state = snmp_task_state.get(device_id)
            if paused_db:
                pause_snmp_task(device_id, reason="health_check_pause_sync")
                continue
            if not state or state.get('paused'):
                schedule_snmp_task(device_id, effective_interval, delay_seconds=0, reason="health_check_missing")
                add_log('warning', f"SNMP pl√°n obnoven√Ω - ch√Ωbal akt√≠vny z√°znam (interval {effective_interval}min)", device['ip'])
                recovered += 1
                continue
            last_check_minutes = None
            if device['last_snmp_check']:
                try:
                    last_check = datetime.fromisoformat(device['last_snmp_check'])
                    last_check_minutes = (current_time - last_check).total_seconds() / 60
                except Exception as e:
                    logger.error(f"Error parsing last_snmp_check for device {device_id}: {e}")
            if last_check_minutes is None or last_check_minutes > effective_interval * 2:
                schedule_snmp_task(device_id, effective_interval, delay_seconds=0, reason="health_check_overdue")
                if last_check_minutes is None:
                    add_log('warning', "SNMP pl√°n obnoven√Ω - nezn√°my ƒças posledn√©ho checku", device['ip'])
                else:
                    add_log('warning', f"SNMP pl√°n obnoven√Ω - posledn√Ω check pred {last_check_minutes:.1f} min", device['ip'])
                recovered += 1
        return recovered
    except Exception as e:
        logger.error(f"Error in SNMP timer health check: {e}")

def scheduled_snmp_health_check():
    """Automatick√° kontrola zdravia SNMP timerov"""
    with app.app_context():
        check_snmp_timers_health()

def start_snmp_timer_for_device(device_id, interval_minutes, immediate=False):
    """Zabezpeƒç√≠ pl√°novanie SNMP √∫lohy pre dan√© zariadenie."""
    delay = 0 if immediate else max(int(interval_minutes), 1) * 60
    schedule_snmp_task(device_id, interval_minutes, delay_seconds=delay, reason="start_device")

def stop_snmp_timer_for_device(device_id):
    """Stop SNMP timer for a specific device"""
    pause_snmp_task(device_id, reason="manual_stop")

def restart_snmp_timer_for_device(device_id, interval_minutes):
    """Restart SNMP timer for a device with new interval"""
    schedule_snmp_task(device_id, interval_minutes, delay_seconds=0, reason="restart")

def start_all_snmp_timers():
    """Start SNMP timers for all devices based on their settings - optimized startup"""
    try:
        with get_db_connection() as conn:
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            global_interval = int(settings.get('snmp_check_interval_minutes', 10))
            devices = conn.execute('SELECT id, name, snmp_interval_minutes, monitoring_paused FROM devices').fetchall()
        ensure_snmp_scheduler_running()
        device_count = len(devices)
        if device_count == 0:
            logger.info("No devices found for SNMP scheduling")
            return
        max_startup_time = min(300, device_count * 15)
        for i, device in enumerate(devices):
            device_interval = device['snmp_interval_minutes'] or 0
            effective_interval = device_interval if device_interval > 0 else global_interval
            effective_interval = max(effective_interval, 1)
            if device['monitoring_paused']:
                pause_snmp_task(device['id'], reason="startup_paused")
                continue
            if device_count == 1:
                start_delay = 30
            else:
                if i == 0:
                    start_delay = 30
                else:
                    start_delay = 30 + ((max_startup_time - 30) * i // (device_count - 1))
            schedule_snmp_task(device['id'], effective_interval, delay_seconds=start_delay, reason="startup")
            if i == 0 or i == device_count - 1:
                logger.info(f"Scheduled SNMP task for device {device['name']} (delay: {start_delay}s)")
    except Exception as e:
        logger.error(f"Error starting SNMP scheduler tasks: {e}")

def stop_all_snmp_timers():
    """Stop all SNMP timers"""
    global snmp_scheduler_thread
    snmp_scheduler_stop.set()
    snmp_scheduler_wakeup.set()
    if snmp_scheduler_thread and snmp_scheduler_thread.is_alive():
        snmp_scheduler_thread.join(timeout=5)
    snmp_scheduler_thread = None
    with snmp_task_lock:
        snmp_task_queue.clear()
        snmp_task_state.clear()
    logger.info("SNMP scheduler stopped")

def setup_scheduler(log_schedule_info=False):
    # V≈ædy vyƒçist√≠me existuj√∫ce √∫lohy, aby sme predi≈°li duplicit√°m alebo star√Ωm nastaveniam
    schedule.clear()

    with get_db_connection() as conn:
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
    
    # SNMP checks are now handled by individual timers - no scheduler needed
    # Only keep essential scheduled tasks
    schedule.every().day.at("03:00").do(scheduled_log_cleanup)  # ƒåistenie star√Ωch logov ka≈æd√Ω de≈à o 3:00
    
    snmp_health_enabled = settings.get('snmp_health_check_enabled', 'true').lower() == 'true'
    try:
        snmp_health_interval = int(settings.get('snmp_health_check_interval_minutes', 15))
    except (TypeError, ValueError):
        snmp_health_interval = 15
    snmp_health_interval = max(1, min(snmp_health_interval, 1440))

    if snmp_health_enabled:
        schedule.every(snmp_health_interval).minutes.do(scheduled_snmp_health_check)
        if log_schedule_info:
            add_log('info', f"SNMP health check je akt√≠vny: ka≈æd√Ωch {snmp_health_interval} min√∫t.")
    elif log_schedule_info:
        add_log('info', "SNMP health check je v nastaveniach vypnut√Ω.")
    
    # Nastavenie automatick√©ho z√°lohovania
    if settings.get('backup_schedule_enabled', 'false').lower() != 'true':
        if log_schedule_info:
            add_log('info', "Automatick√© z√°lohovanie je v nastaveniach vypnut√©.")
        return

    # Ak nie je zadan√Ω ƒças, pou≈æijeme predvolen√Ω, aby sme predi≈°li chybe
    schedule_time = settings.get('backup_schedule_time') or '02:00'
    try:
        if settings.get('backup_schedule_type', 'daily') == 'daily':
            schedule.every().day.at(schedule_time).do(scheduled_backup_job)
            if log_schedule_info:
                add_log('info', f"Automatick√© z√°lohovanie je akt√≠vne: Denne o {schedule_time}.")
        else:
            day = settings.get('backup_schedule_day', 'sunday').lower()
            day_sk = {'monday': 'Pondelok', 'tuesday': 'Utorok', 'wednesday': 'Streda', 'thursday': '≈†tvrtok', 'friday': 'Piatok', 'saturday': 'Sobota', 'sunday': 'Nedeƒæa'}.get(day, day.capitalize())
            getattr(schedule.every(), day).at(schedule_time).do(scheduled_backup_job)
            if log_schedule_info:
                add_log('info', f"Automatick√© z√°lohovanie je akt√≠vne: Ka≈æd√Ω {day_sk} o {schedule_time}.")
    except ValueError as e:
        if log_schedule_info:
            add_log('error', f"Chyba pri nastaven√≠ automatick√©ho z√°lohovania: Neplatn√Ω ƒças '{schedule_time}'. Pou≈æite form√°t HH:MM.")
        logger.error(f"Invalid backup schedule time: {schedule_time}, error: {e}")

    if log_schedule_info:
        # Log current schedule info without SNMP check info
        schedule_info = get_schedule_info()
        if "SNMP" not in schedule_info:  # Only log if we have non-SNMP schedules
            add_log('info', f"Pl√°novaƒç √∫loh: {schedule_info}")

def get_schedule_info():
    """Vr√°ti inform√°cie o pl√°ne automatick√©ho z√°lohovania bez zapisovania do logov"""
    with get_db_connection() as conn:
        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
    
    if settings.get('backup_schedule_enabled', 'false').lower() != 'true':
        return "Automatick√© z√°lohovanie je v nastaveniach vypnut√©."
    
    schedule_time = settings.get('backup_schedule_time') or '02:00'
    try:
        if settings.get('backup_schedule_type', 'daily') == 'daily':
            return f"Automatick√© z√°lohovanie je akt√≠vne: Denne o {schedule_time}."
        else:
            day = settings.get('backup_schedule_day', 'sunday').lower()
            day_sk = {'monday': 'Pondelok', 'tuesday': 'Utorok', 'wednesday': 'Streda', 'thursday': '≈†tvrtok', 'friday': 'Piatok', 'saturday': 'Sobota', 'sunday': 'Nedeƒæa'}.get(day, day.capitalize())
            return f"Automatick√© z√°lohovanie je akt√≠vne: Ka≈æd√Ω {day_sk} o {schedule_time}."
    except Exception as e:
        return f"Chyba pri z√≠skavan√≠ inform√°ci√≠ o pl√°ne: {e}"

# SNMP checks s√∫ spracovan√© centr√°lnym schedulerom (pozri funkcie vy≈°≈°ie)

def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(60)

def scheduled_log_cleanup():
    """Automatick√© ƒçistenie star√Ωch logov"""
    with app.app_context():
        try:
            with get_db_connection() as conn:
                # Z√≠skame nastavenie pre uchov√°vanie logov
                settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
                retention_days = int(settings.get('log_retention_days', 30))
                
                cutoff_date = datetime.now() - timedelta(days=retention_days)
                result = conn.execute('DELETE FROM logs WHERE timestamp < ?', (cutoff_date,))
                deleted_count = result.rowcount
                conn.commit()
                
            if deleted_count > 0:
                add_log('info', f"Automaticky vyƒçisten√© {deleted_count} star√Ωch logov (star≈°√≠ch ako {retention_days} dn√≠)")
        except Exception as e:
            logger.error(f"Chyba pri automatickom ƒçisten√≠ logov: {e}")

# --- Spustenie pl√°novaƒça ---
with app.app_context():
    init_database()
    migrate_existing_passwords()  # Encrypt existing plaintext passwords
    setup_scheduler(log_schedule_info=False)  # Pri ≈°tarte aplik√°cie nelogujeme info o schedule
    start_all_snmp_timers()  # Spustenie SNMP timerov pre v≈°etky zariadenia

threading.Thread(target=run_scheduler, daemon=True).start()

logger.info("Aplik√°cia MikroTik Manager sa sp√∫≈°≈•a...")

# === PING MONITORING FUNKCIE ===

def ping_device(ip, count=1, timeout=None):
    """Ping zariadenie a vr√°≈• ≈°tatistiky - optimalizovan√© pre r√Ωchle intervaly"""
    try:
        # Pou≈æi≈• timeout z parametra alebo default hodnotu
        if timeout is None:
            with get_db_connection() as conn:
                cursor = conn.cursor()
                timeout_setting = cursor.execute('SELECT value FROM settings WHERE key = ?', ('ping_timeout',)).fetchone()
                timeout = int(timeout_setting['value']) if timeout_setting else 1
        
        # Pre r√Ωchle intervaly pou≈æ√≠vame len 1 ping s nastaven√Ωm timeout
        result = subprocess.run(['ping', '-c', str(count), '-W', str(timeout), ip], 
                              capture_output=True, text=True, timeout=timeout + 2)  # Prid√°me +2s buffer pre subprocess timeout
        
        if result.returncode == 0:
            # Parsovanie v√Ωsledkov
            output = result.stdout
            
            # Packet loss
            loss_match = re.search(r'(\d+)% packet loss', output)
            packet_loss = int(loss_match.group(1)) if loss_match else 0
            
            # Average latency
            time_matches = re.findall(r'time=(\d+\.?\d*)', output)
            if time_matches:
                avg_latency = sum(float(t) for t in time_matches) / len(time_matches)
            else:
                avg_latency = None
                
            return {
                'status': 'online',
                'packet_loss': packet_loss,
                'avg_latency': avg_latency,
                'timestamp': datetime.now().isoformat()
            }
        else:
            return {
                'status': 'offline',
                'packet_loss': 100,
                'avg_latency': None,
                'timestamp': datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"Chyba pri ping-ovan√≠ {ip}: {e}")
        return {
            'status': 'offline',
            'packet_loss': 100,
            'avg_latency': None,
            'timestamp': datetime.now().isoformat()
        }

def save_ping_result(device_id, ping_result):
    """Ulo≈æ√≠ ping v√Ωsledok do datab√°zy"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO ping_history (device_id, timestamp, avg_latency, packet_loss, status)
                VALUES (?, ?, ?, ?, ?)
            ''', (device_id, ping_result['timestamp'], ping_result['avg_latency'], 
                  ping_result['packet_loss'], ping_result['status']))
            
            # Aktualizujeme stav zariadenia v devices tabuƒæke
            cursor.execute('UPDATE devices SET status = ? WHERE id = ?', (ping_result['status'], device_id))
            
            conn.commit()
            
            # Vyƒçist√≠me star√© z√°znamy podƒæa nastavenia (default 30 dn√≠ pre ping history)
            settings = {row['key']: row['value'] for row in cursor.execute('SELECT key, value FROM settings').fetchall()}
            ping_retention_days = int(settings.get('ping_retention_days', 30))
            cutoff_date = datetime.now() - timedelta(days=ping_retention_days)
            cursor.execute('DELETE FROM ping_history WHERE timestamp < ?', (cutoff_date.isoformat(),))
            conn.commit()
            
    except Exception as e:
        logger.error(f"Chyba pri ukladan√≠ ping v√Ωsledku: {e}")

def save_snmp_history(device_id, snmp_data):
    """Ulo≈æ√≠ SNMP d√°ta do history tabuƒæky"""
    try:
        # Offline alebo pr√°zdne SNMP d√°ta by nemali vytv√°ra≈• falo≈°n√© z√°pisy
        if not snmp_data or snmp_data.get('uptime') in (None, 'N/A'):
            return
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO snmp_history (device_id, timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (device_id, datetime.now().isoformat(), 
                  snmp_data.get('cpu_load'), snmp_data.get('temperature'),
                  snmp_data.get('memory_usage'), snmp_data.get('uptime'),
                  snmp_data.get('total_memory'), snmp_data.get('free_memory')))
            conn.commit()
            
            # Vyƒçist√≠me star√© z√°znamy podƒæa nastavenia (default 30 dn√≠ pre SNMP history)
            settings = {row['key']: row['value'] for row in cursor.execute('SELECT key, value FROM settings').fetchall()}
            snmp_retention_days = int(settings.get('snmp_retention_days', 30))
            cutoff_date = datetime.now() - timedelta(days=snmp_retention_days)
            cursor.execute('DELETE FROM snmp_history WHERE timestamp < ?', (cutoff_date.isoformat(),))
            conn.commit()
            
    except Exception as e:
        logger.error(f"Chyba pri ukladan√≠ SNMP history: {e}")

def _safe_int(value):
    try:
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return int(float(value))
        text = str(value).strip()
        if not text or text.upper() == 'N/A':
            return None
        text = text.replace('%', '').replace(',', '.')
        return int(float(text))
    except (ValueError, TypeError):
        return None

def _format_duration_from_seconds(seconds):
    try:
        total_seconds = int(seconds)
    except (TypeError, ValueError):
        return "0m"
    minutes, _ = divmod(total_seconds, 60)
    hours, minutes = divmod(minutes, 60)
    days, hours = divmod(hours, 24)
    parts = []
    if days:
        parts.append(f"{days}d")
    if hours or days:
        parts.append(f"{hours}h")
    parts.append(f"{minutes}m")
    return ' '.join(parts)

def evaluate_snmp_notifications(device, snmp_data, previous_data):
    """Vyhodnot√≠ SNMP notifik√°cie podƒæa kritick√Ωch limitov a zmien."""
    try:
        with get_db_connection() as conn:
            keys = ['temp_critical_threshold', 'cpu_critical_threshold', 'memory_critical_threshold']
            placeholders = ','.join('?' for _ in keys)
            rows = conn.execute(f'SELECT key, value FROM settings WHERE key IN ({placeholders})', keys).fetchall()
            settings = {row['key']: row['value'] for row in rows}
    except Exception as e:
        add_log('warning', f"Nepodarilo sa naƒç√≠ta≈• nastavenia SNMP notifik√°ci√≠: {e}", device['ip'])
        return

    temperature_threshold = _safe_int(settings.get('temp_critical_threshold'))
    cpu_threshold = _safe_int(settings.get('cpu_critical_threshold'))
    memory_threshold = _safe_int(settings.get('memory_critical_threshold'))

    current_temperature = _safe_int(snmp_data.get('temperature'))
    previous_temperature = _safe_int((previous_data or {}).get('temperature'))
    if (
        temperature_threshold is not None
        and current_temperature is not None
        and current_temperature >= temperature_threshold
        and (previous_temperature is None or previous_temperature < temperature_threshold)
    ):
        message = (
            f"üå°Ô∏è MikroTik {device['name']} ({device['ip']}) prekroƒçil kritick√∫ teplotu: "
            f"{current_temperature}¬∞C (limit {temperature_threshold}¬∞C)"
        )
        add_log('warning', message, device['ip'])
        send_pushover_notification(
            message,
            title="SNMP Monitor - Teplota",
            notification_key='notify_temp_critical'
        )

    current_cpu = _safe_int(snmp_data.get('cpu_load'))
    previous_cpu = _safe_int((previous_data or {}).get('cpu_load'))
    if (
        cpu_threshold is not None
        and current_cpu is not None
        and current_cpu >= cpu_threshold
        and (previous_cpu is None or previous_cpu < cpu_threshold)
    ):
        message = (
            f"üñ•Ô∏è MikroTik {device['name']} ({device['ip']}) prekroƒçil kritick√© vy≈•a≈æenie CPU: "
            f"{current_cpu}% (limit {cpu_threshold}%)"
        )
        add_log('warning', message, device['ip'])
        send_pushover_notification(
            message,
            title="SNMP Monitor - CPU",
            notification_key='notify_cpu_critical'
        )

    current_memory = _safe_int(snmp_data.get('memory_usage'))
    previous_memory = _safe_int((previous_data or {}).get('memory_usage'))
    if (
        memory_threshold is not None
        and current_memory is not None
        and current_memory >= memory_threshold
        and (previous_memory is None or previous_memory < memory_threshold)
    ):
        message = (
            f"üíæ MikroTik {device['name']} ({device['ip']}) prekroƒçil kritick√© vyu≈æitie pam√§te: "
            f"{current_memory}% (limit {memory_threshold}%)"
        )
        add_log('warning', message, device['ip'])
        send_pushover_notification(
            message,
            title="SNMP Monitor - Pam√§≈•",
            notification_key='notify_memory_critical'
        )

    current_uptime = _safe_int(snmp_data.get('uptime_seconds')) if snmp_data.get('uptime') != 'N/A' else None
    previous_uptime = _safe_int((previous_data or {}).get('uptime_seconds'))
    if (
        previous_uptime is not None
        and current_uptime is not None
        and previous_uptime > current_uptime + 300
        and previous_uptime > 600
    ):
        uptime_human = _format_duration_from_seconds(current_uptime)
        message = (
            f"üîÑ MikroTik {device['name']} ({device['ip']}) bol re≈°tartovan√Ω "
            f"(aktu√°lny uptime {uptime_human})"
        )
        add_log('warning', message, device['ip'])
        send_pushover_notification(
            message,
            title="SNMP Monitor - Reboot",
            notification_key='notify_reboot_detected'
        )

    current_version = snmp_data.get('version')
    previous_version = (previous_data or {}).get('version')
    if (
        previous_version
        and current_version
        and previous_version != 'N/A'
        and current_version != 'N/A'
        and previous_version != current_version
    ):
        message = (
            f"üÜï MikroTik {device['name']} ({device['ip']}) m√° nov√∫ verziu RouterOS: "
            f"{previous_version} ‚ûú {current_version}"
        )
        add_log('info', message, device['ip'])
        send_pushover_notification(
            message,
            title="SNMP Monitor - Verzia OS",
            notification_key='notify_version_change'
        )
def ping_monitoring_loop():
    """Nekoneƒçn√° sluƒçka pre ping monitoring s presn√Ωm dodr≈æan√≠m intervalov pre ka≈æd√© zariadenie"""
    global ping_thread_stop_flag
    
    # Slovn√≠k pre sledovanie posledn√©ho ping ƒçasu ka≈æd√©ho zariadenia v pam√§ti
    device_last_ping = {}
    
    # Slovn√≠k pre sledovanie stavu zariaden√≠ a poƒçtu ne√∫spe≈°n√Ωch pingov
    device_status_tracker = {}
    
    while not ping_thread_stop_flag.is_set():
        try:
            # Naƒç√≠tame nastavenia pre ping monitoring
            with get_db_connection() as conn:
                cursor = conn.cursor()
                settings_rows = cursor.execute('''
                    SELECT key, value FROM settings 
                    WHERE key IN (?, ?, ?, ?, ?)
                ''', ('ping_check_interval_seconds', 'ping_monitor_enabled', 'ping_retry_interval', 
                     'ping_retries', 'ping_timeout')).fetchall()
                settings = {row['key']: row['value'] for row in settings_rows}
                
                # Kontrola ƒçi je ping monitoring povolen√Ω
                ping_enabled = settings.get('ping_monitor_enabled', 'true').lower() == 'true'
                global_ping_interval = int(settings.get('ping_check_interval_seconds', '120'))  # Default 2 min√∫ty
                retry_interval = int(settings.get('ping_retry_interval', '20'))  # Default 20 sek√∫nd
                max_retries = int(settings.get('ping_retries', '3'))  # Default 3 pokusy
                ping_timeout = int(settings.get('ping_timeout', '5'))  # Default 5 sek√∫nd
                
                if not ping_enabled:
                    logger.info("Ping monitoring je zak√°zan√Ω")
                    # Poƒçk√°me 60 sek√∫nd alebo stop signal
                    if ping_thread_stop_flag.wait(timeout=60):
                        break
                    continue
                
                # Z√≠skaj zariadenia s ich ping interval nastaveniami (okrem paused zariaden√≠)
                cursor.execute('''
                    SELECT id, name, ip, ping_interval_seconds, ping_retry_interval_seconds, status
                    FROM devices
                    WHERE monitoring_paused = 0 OR monitoring_paused IS NULL
                ''')
                devices = cursor.fetchall()
                
                current_time = datetime.now()
                devices_to_ping = []
                
                # Najkrat≈°√≠ interval pre dynamick√© nastavenie check intervalu
                shortest_interval = global_ping_interval
                
                for device in devices:
                    device_id, device_name, ip, device_ping_interval, device_ping_retry_interval, db_status = device
                    
                    # Inici√°lne nastavenie tracker-a pre zariadenie ak neexistuje
                    if device_id not in device_status_tracker:
                        device_status_tracker[device_id] = {
                            'name': device_name,
                            'status': db_status or 'unknown',
                            'failed_count': 0,
                            'last_status_change': current_time,
                            'in_retry_mode': False
                        }
                    else:
                        device_status_tracker[device_id]['name'] = device_name
                    
                    # Pou≈æij device-specific interval, ak je nastaven√Ω, inak global
                    effective_interval = device_ping_interval if device_ping_interval and device_ping_interval > 0 else global_ping_interval
                    device_effective_retry = device_ping_retry_interval if device_ping_retry_interval and device_ping_retry_interval > 0 else retry_interval
                    
                    # Ak je zariadenie v retry mode, pou≈æijeme retry interval namiesto norm√°lneho
                    if device_status_tracker[device_id]['in_retry_mode']:
                        effective_interval = device_effective_retry
                    
                    # Sleduj najkrat≈°√≠ interval
                    if effective_interval < shortest_interval:
                        shortest_interval = effective_interval
                    
                    # Kontrola pre ka≈æd√© zariadenie individu√°lne
                    should_ping = False
                    
                    if device_id not in device_last_ping:
                        # Prv√Ω ping - pinguj okam≈æite
                        should_ping = True
                        debug_log('debug_ping_monitoring', f"Device {ip} ({device_name}) (ID: {device_id}): prv√Ω ping, interval: {effective_interval}s")
                    else:
                        # Kontrola ƒçasu od posledn√©ho pingu pre toto zariadenie
                        seconds_since_ping = (current_time - device_last_ping[device_id]).total_seconds()
                        
                        if seconds_since_ping >= effective_interval:
                            should_ping = True
                            if device_status_tracker[device_id]['in_retry_mode']:
                                debug_log('debug_ping_monitoring', 
                                          f"Device {ip} ({device_name}) (ID: {device_id}): retry ping, failed count: {device_status_tracker[device_id]['failed_count']}")
                            else:
                                debug_log('debug_ping_monitoring', 
                                          f"Device {ip} ({device_name}) (ID: {device_id}): {seconds_since_ping:.2f}s od posledn√©ho pingu (interval: {effective_interval}s)")
                        else:
                            remaining = effective_interval - seconds_since_ping
                            debug_log('debug_ping_monitoring', 
                                      f"Device {ip} ({device_name}) (ID: {device_id}): zost√°va {remaining:.2f}s do ƒèal≈°ieho pingu")
                    
                    if should_ping:
                        devices_to_ping.append((device_id, device_name, ip, effective_interval, device_effective_retry, max_retries, ping_timeout))
                
                # Ping v≈°etky zariadenia, ktor√© potrebuj√∫ ping - spust√≠me ich paralelne pre presnos≈•
                if devices_to_ping:
                    import concurrent.futures
                    import threading
                    
                    def ping_single_device(device_info):
                        device_id, device_name, ip, interval, retry_interval, max_retries, ping_timeout = device_info
                        try:
                            # Zaznaƒç√≠me ƒças PRED pingom pre presnos≈•
                            ping_time = datetime.now()
                            device_last_ping[device_id] = ping_time
                            
                            # Pre kr√°tke intervaly pou≈æ√≠vame r√Ωchly ping
                            ping_result = ping_device(ip, count=1 if interval <= 10 else 2, timeout=ping_timeout)
                            
                            # Spracovanie v√Ωsledku pingu
                            current_status = device_status_tracker[device_id]['status']
                            in_retry_mode = device_status_tracker[device_id]['in_retry_mode']
                            failed_count = device_status_tracker[device_id]['failed_count']
                            
                            if ping_result['status'] == 'online':
                                # √öspe≈°n√Ω ping - zariadenie je online
                                if current_status != 'online':
                                    # Zariadenie bolo offline a teraz je online - zmena stavu
                                    add_log('info', f"MikroTik {device_name} ({ip}) je op√§≈• online")
                                    send_pushover_notification(
                                        f"üü¢ MikroTik {device_name} ({ip}) je op√§≈• online",
                                        title="MikroTik Monitor - Zariadenie Online",
                                        notification_key='notify_device_online'
                                    )
                                    trigger_immediate_snmp_check_for_device(device_id, reason="ping_online_recovery")
                                
                                # Reset retry counter and mode
                                device_status_tracker[device_id] = {
                                    'name': device_name,
                                    'status': 'online',
                                    'failed_count': 0,
                                    'last_status_change': datetime.now(),
                                    'in_retry_mode': False
                                }
                            else:
                                # Ne√∫spe≈°n√Ω ping
                                if not in_retry_mode:
                                    # Prv√Ω ne√∫spe≈°n√Ω ping - prejdi do retry mode
                                    device_status_tracker[device_id]['in_retry_mode'] = True
                                    device_status_tracker[device_id]['failed_count'] = 1
                                    debug_log('debug_ping_monitoring', 
                                              f"Device {ip} (ID: {device_id}): Prv√Ω ne√∫spe≈°n√Ω ping - prejdem do retry mode (1/{max_retries})")
                                else:
                                    # U≈æ v retry mode - zv√Ω≈° poƒç√≠tadlo
                                    device_status_tracker[device_id]['failed_count'] += 1
                                    debug_log('debug_ping_monitoring', 
                                              f"Device {ip} (ID: {device_id}): Ne√∫spe≈°n√Ω ping {device_status_tracker[device_id]['failed_count']}/{max_retries}")
                                
                                # Kontrola ƒçi sme dosiahli maxim√°lny poƒçet ne√∫spe≈°n√Ωch pokusov
                                if device_status_tracker[device_id]['failed_count'] >= max_retries:
                                    if current_status != 'offline':
                                        # Zmena stavu na offline
                                        device_status_tracker[device_id]['status'] = 'offline'
                                        device_status_tracker[device_id]['last_status_change'] = datetime.now()
                                        add_log('error', f"MikroTik {device_name} ({ip}) je offline (po {max_retries} ne√∫spe≈°n√Ωch pokusoch)")
                                        send_pushover_notification(
                                            f"üî¥ MikroTik {device_name} ({ip}) je offline",
                                            title="MikroTik Monitor - Zariadenie Offline",
                                            notification_key='notify_device_offline'
                                        )
                                        # Naƒèalej zost√°vame v retry mode pre monitoring
                            
                            # Ulo≈æ√≠me v√Ωsledok a aktu√°lny status
                            ping_result['status'] = device_status_tracker[device_id]['status']
                            save_ping_result(device_id, ping_result)
                            
                            # Aktualizujeme stav v datab√°ze
                            with get_db_connection() as conn:
                                conn.execute('UPDATE devices SET status = ? WHERE id = ?', 
                                             (device_status_tracker[device_id]['status'], device_id))
                                conn.commit()
                            
                            # Po≈°leme update cez WebSocket
                            debug_emit('ping_update', {
                                'device_id': device_id,
                                'status': ping_result['status'],
                                'avg_latency': ping_result['avg_latency'],
                                'packet_loss': ping_result['packet_loss'],
                                'timestamp': ping_result['timestamp']
                            })
                            
                            logger.info(f"Ping {ip} (interval: {interval}s): {ping_result['status']}, "
                                      f"latencia: {ping_result['avg_latency']}ms, "
                                      f"packet loss: {ping_result['packet_loss']}%")
                            
                        except Exception as e:
                            logger.error(f"Chyba pri pingu zariadenia {ip}: {e}")
                    
                    # Paralelne pingujeme v≈°etky zariadenia naraz pre presnos≈• ƒçasovania
                    with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(devices_to_ping), 20)) as executor:
                        futures = [executor.submit(ping_single_device, device_info) for device_info in devices_to_ping]
                        # Krat≈°√≠ timeout pre r√Ωchle intervaly
                        timeout = min(10, shortest_interval / 2) if shortest_interval < 10 else 15
                        concurrent.futures.wait(futures, timeout=timeout)
                
                # Optimalizovan√© nastavenie check intervalu - menej pr√≠sne pre lep≈°√≠ v√Ωkon
                if shortest_interval <= 1:
                    next_check_interval = 0.2  # Kontrola ka≈æd√Ωch 200ms pre sub-sekundov√© intervaly (bolo 0.1s)
                elif shortest_interval <= 5:
                    next_check_interval = 0.5  # Kontrola ka≈æd√Ωch 500ms pre kr√°tke intervaly (bolo 0.2s)
                elif shortest_interval <= 30:
                    next_check_interval = 1.0  # Kontrola ka≈æd√∫ sekundu pre stredn√© intervaly (bolo 0.5s)
                elif shortest_interval <= 120:
                    next_check_interval = 2.0  # Kontrola ka≈æd√© 2 sekundy pre dlh√© intervaly
                else:
                    next_check_interval = 5.0   # Kontrola ka≈æd√Ωch 5 sek√∫nd pre veƒæmi dlh√© intervaly
                
                debug_log('debug_ping_monitoring', f"Ping monitoring: pingovan√© {len(devices_to_ping)} zariaden√≠, najkrat≈°√≠ interval: {shortest_interval}s, ƒèal≈°ia kontrola za {next_check_interval}s")
                    
        except Exception as e:
            logger.error(f"Chyba v ping monitoring loop: {e}")
            next_check_interval = 5  # Fallback pri chybe
        
        # Dynamick√Ω check interval pre maxim√°lnu presnos≈•
        if ping_thread_stop_flag.wait(timeout=next_check_interval):
            break
    
    logger.info("Ping monitoring loop ukonƒçen√Ω")

# === MONITORING API ENDPOINTY ===

@app.route('/api/monitoring/device/<int:device_id>/settings', methods=['GET', 'POST'])
@login_required
def monitoring_device_settings(device_id):
    """Z√≠ska alebo nastav√≠ monitoring nastavenia pre konkr√©tne zariadenie"""
    if request.method == 'GET':
        try:
            with get_db_connection() as conn:
                device = conn.execute('''
                    SELECT id, name, ip, ping_interval_seconds, ping_retry_interval_seconds, snmp_interval_minutes, monitoring_paused 
                    FROM devices WHERE id = ?
                ''', (device_id,)).fetchone()
                
                if not device:
                    return jsonify({'status': 'error', 'message': 'Zariadenie nen√°jden√©'}), 404
                
                # Z√≠skaj glob√°lne nastavenia
                settings = {row['key']: row['value'] for row in 
                           conn.execute('SELECT key, value FROM settings WHERE key IN (?, ?, ?)', 
                                      ('ping_check_interval_seconds', 'ping_retry_interval', 'snmp_check_interval_minutes')).fetchall()}
                
                return jsonify({
                    'device': {
                        'id': device[0],
                        'name': device[1], 
                        'ip': device[2],
                        'ping_interval_seconds': device[3] or 0,
                        'ping_retry_interval_seconds': device[4] or 0,
                        'snmp_interval_minutes': device[5] or 0,
                        'monitoring_paused': bool(device[6])
                    },
                    'global_settings': {
                        'ping_interval_seconds': int(settings.get('ping_check_interval_seconds', 120)),
                        'ping_retry_interval_seconds': int(settings.get('ping_retry_interval', 20)),
                        'snmp_interval_minutes': int(settings.get('snmp_check_interval_minutes', 10))
                    }
                })
        except Exception as e:
            logger.error(f"Chyba pri z√≠skavan√≠ device settings: {e}")
            return jsonify({'status': 'error', 'message': str(e)}), 500
    
    elif request.method == 'POST':
        try:
            data = request.json
            ping_interval = data.get('ping_interval_seconds', 0)
            ping_retry_interval = data.get('ping_retry_interval_seconds', 0)
            snmp_interval = data.get('snmp_interval_minutes', 0)
            
            # Valid√°cia
            if ping_interval < 0 or ping_interval > 86400:  # 0-24 hod√≠n
                return jsonify({'status': 'error', 'message': 'Ping interval mus√≠ by≈• 0-86400 sek√∫nd'}), 400
            if ping_interval > 0 and ping_interval < 20:
                return jsonify({'status': 'error', 'message': 'Ping interval mus√≠ by≈• 0 (glob√°lne) alebo minim√°lne 20 sek√∫nd'}), 400
            if ping_retry_interval < 0 or ping_retry_interval > 120:
                return jsonify({'status': 'error', 'message': 'Retry interval mus√≠ by≈• 0 (glob√°lne) alebo 5-120 sek√∫nd'}), 400
            if 0 < ping_retry_interval < 5:
                return jsonify({'status': 'error', 'message': 'Retry interval mus√≠ by≈• 0 (glob√°lne) alebo 5-120 sek√∫nd'}), 400
            if snmp_interval < 0 or snmp_interval > 1440:  # 0-24 hod√≠n
                return jsonify({'status': 'error', 'message': 'SNMP interval mus√≠ by≈• 0-1440 min√∫t'}), 400
            
            with get_db_connection() as conn:
                # Get old SNMP interval before update
                old_device = conn.execute('SELECT snmp_interval_minutes FROM devices WHERE id = ?', (device_id,)).fetchone()
                old_snmp_interval = old_device[0] if old_device else 0
                
                conn.execute('''
                    UPDATE devices 
                    SET ping_interval_seconds = ?, ping_retry_interval_seconds = ?, snmp_interval_minutes = ?
                    WHERE id = ?
                ''', (ping_interval, ping_retry_interval, snmp_interval, device_id))
                conn.commit()
                
                device = conn.execute('SELECT name, ip FROM devices WHERE id = ?', (device_id,)).fetchone()
                if device:
                    add_log('info', f"Monitoring nastavenia aktualizovan√© pre {device[1]} ({device[0]}): ping {ping_interval}s, retry {ping_retry_interval}s, SNMP {snmp_interval}min")
                
                # Restart SNMP timer if interval changed
                if old_snmp_interval != snmp_interval:
                    if snmp_interval > 0:
                        restart_snmp_timer_for_device(device_id, snmp_interval)
                    else:
                        # Use global interval
                        settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
                        global_interval = int(settings.get('snmp_check_interval_minutes', 10))
                        restart_snmp_timer_for_device(device_id, global_interval)
                
            return jsonify({'status': 'success', 'message': 'Nastavenia ulo≈æen√©'})
            
        except Exception as e:
            logger.error(f"Chyba pri ukladan√≠ device settings: {e}")
            return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/device/<int:device_id>/pause', methods=['POST'])
@login_required
def monitoring_device_pause_resume(device_id):
    """Toggle pause/resume monitoring pre zariadenie"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # Skontroluj ƒçi zariadenie existuje a z√≠skaj aktu√°lny stav
            device_data = cursor.execute('SELECT name, ip, monitoring_paused FROM devices WHERE id = ?', (device_id,)).fetchone()
            if not device_data:
                return jsonify({'status': 'error', 'message': 'Zariadenie nen√°jden√©'}), 404
            
            device_name, device_ip, current_paused = device_data
            
            # Toggle stav - ak je NULL alebo 0, nastav na 1, inak nastav na 0
            new_paused = 0 if current_paused else 1
            
            # Aktualizuj monitoring_paused status
            cursor.execute('''
                UPDATE devices 
                SET monitoring_paused = ?
                WHERE id = ?
            ''', (new_paused, device_id))
            conn.commit()
            
            # Zastav/spusti SNMP timer pre toto zariadenie
            if new_paused:
                stop_snmp_timer_for_device(device_id)
            else:
                # Z√≠skaj spr√°vny interval pre toto zariadenie pred spusten√≠m timera
                device_info = cursor.execute('SELECT snmp_interval_minutes FROM devices WHERE id = ?', (device_id,)).fetchone()
                device_interval = device_info[0] if device_info and device_info[0] else 0
                
                # Ak device nem√° vlastn√Ω interval, pou≈æij glob√°lny
                if device_interval <= 0:
                    settings = {row['key']: row['value'] for row in cursor.execute('SELECT key, value FROM settings').fetchall()}
                    device_interval = int(settings.get('snmp_check_interval_minutes', 10))
                
                start_snmp_timer_for_device(device_id, device_interval, immediate=False)
            
            action_text = 'pozastaven√Ω' if new_paused else 'obnoven√Ω'
            
            add_log('info', f"Monitoring {action_text} pre {device_name} ({device_ip})")
            logger.info(f"Monitoring {action_text} pre zariadenie {device_name} ({device_ip}) - ID: {device_id}")
            
            return jsonify({
                'status': 'success',
                'monitoring_paused': bool(new_paused),
                'message': f'Monitoring {action_text} pre {device_name}'
            })
            
    except Exception as e:
        logger.error(f"Chyba pri zmene monitoring stavu pre zariadenie {device_id}: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/ping/manual/<int:device_id>', methods=['POST'])
@login_required
def manual_ping_device(device_id):
    """Manu√°lny ping zariadenia"""
    try:
        with get_db_connection() as conn:
            device = conn.execute('SELECT ip, name FROM devices WHERE id = ?', (device_id,)).fetchone()
            
            if not device:
                return jsonify({'status': 'error', 'message': 'Zariadenie nen√°jden√©'}), 404
            
            # Naƒç√≠taj ping_timeout nastavenie
            ping_timeout = conn.execute('SELECT value FROM settings WHERE key = ?', ('ping_timeout',)).fetchone()
            timeout = int(ping_timeout['value']) if ping_timeout else 5
            
            ip, name = device
            ping_result = ping_device(ip, timeout=timeout)
            save_ping_result(device_id, ping_result)
            
            # Po≈°leme update cez WebSocket
            debug_emit('ping_update', {
                'device_id': device_id,
                'status': ping_result['status'],
                'avg_latency': ping_result['avg_latency'],
                'packet_loss': ping_result['packet_loss'],
                'timestamp': ping_result['timestamp']
            })
            
            add_log('info', f"Manu√°lny ping {ip} ({name}): {ping_result['status']}")
            return jsonify(ping_result)
            
    except Exception as e:
        logger.error(f"Chyba pri manu√°lnom ping: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/debug/settings')
@login_required
def debug_monitoring_settings():
    """Debug endpoint pre kontrolu ping monitoring nastaven√≠"""
    try:
        with get_db_connection() as conn:
            # Z√≠skaj glob√°lne nastavenia
            settings = {row['key']: row['value'] for row in 
                       conn.execute('SELECT key, value FROM settings WHERE key LIKE "%ping%"').fetchall()}
            
            # Z√≠skaj device nastavenia
            devices = conn.execute('''
                SELECT id, name, ip, ping_interval_seconds, ping_retry_interval_seconds,
                       (SELECT MAX(timestamp) FROM ping_history WHERE device_id = devices.id) as last_ping
                FROM devices
            ''').fetchall()
            
            device_info = []
            current_time = datetime.now()
            for device in devices:
                device_id, name, ip, device_ping_interval, device_retry_interval, last_ping_str = device
                
                global_ping_interval = int(settings.get('ping_check_interval_seconds', '120'))
                effective_interval = device_ping_interval if device_ping_interval and device_ping_interval > 0 else global_ping_interval
                global_retry_interval = int(settings.get('ping_retry_interval', '20'))
                effective_retry_interval = device_retry_interval if device_retry_interval and device_retry_interval > 0 else global_retry_interval
                
                seconds_since_ping = None
                if last_ping_str:
                    try:
                        last_ping = datetime.fromisoformat(last_ping_str)
                        seconds_since_ping = (current_time - last_ping).total_seconds()
                    except:
                        pass
                
                device_info.append({
                    'id': device_id,
                    'name': name,
                    'ip': ip,
                    'device_ping_interval': device_ping_interval,
                    'device_retry_interval': device_retry_interval,
                    'effective_interval': effective_interval,
                    'effective_retry_interval': effective_retry_interval,
                    'last_ping': last_ping_str,
                    'seconds_since_ping': seconds_since_ping,
                    'should_ping_soon': seconds_since_ping is None or seconds_since_ping >= effective_interval
                })
            
            return jsonify({
                'global_settings': settings,
                'devices': device_info,
                'ping_thread_running': ping_thread and ping_thread.is_alive() if 'ping_thread' in globals() else False
            })
            
    except Exception as e:
        logger.error(f"Chyba pri debug monitoring settings: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/ping/<int:device_id>')
@login_required
def get_ping_history(device_id):
    """Vr√°ti ping hist√≥riu pre zariadenie"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            # Posledn√Ωch 24 hod√≠n
            day_ago = datetime.now() - timedelta(hours=24)
            cursor.execute('''
                SELECT timestamp, avg_latency, packet_loss, status
                FROM ping_history 
                WHERE device_id = ? AND timestamp > ?
                ORDER BY timestamp ASC
            ''', (device_id, day_ago.isoformat()))
            
            history = []
            for row in cursor.fetchall():
                history.append({
                    'timestamp': row[0],
                    'avg_latency': row[1],
                    'packet_loss': row[2],
                    'status': row[3]
                })
            
            return jsonify(history)
            
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ ping hist√≥rie: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/ping/current/<int:device_id>')
@login_required  
def get_current_ping_status(device_id):
    """Vr√°ti aktu√°lny ping status pre zariadenie"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # Z√≠skaj zariadenie a ping timeout nastavenie
            cursor.execute('SELECT ip FROM devices WHERE id = ?', (device_id,))
            result = cursor.fetchone()
            
            if not result:
                return jsonify({'status': 'error', 'message': 'Zariadenie nen√°jden√©'}), 404
            
            # Naƒç√≠taj ping_timeout nastavenie
            ping_timeout = cursor.execute('SELECT value FROM settings WHERE key = ?', ('ping_timeout',)).fetchone()
            timeout = int(ping_timeout['value']) if ping_timeout else 5
                
            ip = result[0]
            ping_result = ping_device(ip, timeout=timeout)
            save_ping_result(device_id, ping_result)
            
            return jsonify(ping_result)
            
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ aktu√°lneho ping stavu: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/ping-status')
@login_required
def get_all_ping_status():
    """Vr√°ti posledn√© ping statusy pre v≈°etky zariadenia"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            # Z√≠skaj posledn√Ω ping status pre ka≈æd√© zariadenie
            cursor.execute('''
                SELECT DISTINCT p.device_id, p.status, p.avg_latency, p.packet_loss, p.timestamp
                FROM ping_history p
                INNER JOIN (
                    SELECT device_id, MAX(timestamp) as latest_timestamp
                    FROM ping_history
                    GROUP BY device_id
                ) latest ON p.device_id = latest.device_id AND p.timestamp = latest.latest_timestamp
                ORDER BY p.device_id
            ''')
            
            results = cursor.fetchall()
            ping_statuses = []
            
            for row in results:
                ping_statuses.append({
                    'device_id': row[0],
                    'success': row[1] == 'online',  # Convert status to boolean
                    'avg_latency': row[2],
                    'packet_loss': row[3] or 0,
                    'timestamp': row[4]
                })
            
            return jsonify(ping_statuses)
            
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ ping statusov: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/snmp/<int:device_id>')
@login_required
def get_snmp_history(device_id):
    """Vr√°ti SNMP hist√≥riu pre zariadenie"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            # Posledn√Ωch 24 hod√≠n
            day_ago = datetime.now() - timedelta(hours=24)
            cursor.execute('''
                SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                FROM snmp_history 
                WHERE device_id = ? AND timestamp > ?
                ORDER BY timestamp ASC
            ''', (device_id, day_ago.isoformat()))
            
            history = []
            for row in cursor.fetchall():
                total_mem = row[5]
                free_mem = row[6]
                used_mem = (total_mem - free_mem) if total_mem and free_mem else None
                
                history.append({
                    'timestamp': row[0],
                    'cpu_load': row[1],
                    'temperature': row[2],
                    'memory_usage': row[3],
                    'uptime': row[4],
                    'total_memory': total_mem,  # MB
                    'free_memory': free_mem,    # MB
                    'used_memory': used_mem     # MB (vypoƒç√≠tan√©)
                })
            
            return jsonify(history)
            
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ SNMP hist√≥rie: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/availability/<int:device_id>')
@login_required
def get_availability_history(device_id):
    """Vr√°ti availability ≈°tatistiky pre posledn√Ωch 7 dn√≠"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            availability_data = []
            for i in range(7):
                date = datetime.now() - timedelta(days=i)
                start_of_day = date.replace(hour=0, minute=0, second=0, microsecond=0)
                end_of_day = date.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                # Spoƒç√≠tame ping z√°znamy pre dan√Ω de≈à
                cursor.execute('''
                    SELECT COUNT(*) as total,
                           SUM(CASE WHEN status = 'online' THEN 1 ELSE 0 END) as online
                    FROM ping_history 
                    WHERE device_id = ? AND timestamp BETWEEN ? AND ?
                ''', (device_id, start_of_day.isoformat(), end_of_day.isoformat()))
                
                result = cursor.fetchone()
                total = result[0] if result[0] else 0
                online = result[1] if result[1] else 0
                
                percentage = (online / total * 100) if total > 0 else 0
                
                availability_data.append({
                    'date': date.strftime('%d.%m'),
                    'percentage': round(percentage, 2)
                })
            
            # Otoƒç√≠me poradie (najstar≈°√≠ de≈à prv√Ω)
            availability_data.reverse()
            return jsonify(availability_data)
            
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ availability d√°t: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/monitoring/history/<int:device_id>')
@login_required
def get_monitoring_history(device_id):
    """Vr√°ti monitoring d√°ta pre zadan√Ω ƒçasov√Ω rozsah"""
    try:
        # Z√≠skame parametre z query string
        time_range = request.args.get('range', '24h')  # default 24h
        
        # V√Ωpoƒçet ƒçasov√©ho rozsahu
        now = datetime.now()
        time_mappings = {
            'recent': timedelta(hours=1),       # Posledn√° hodina
            '3h': timedelta(hours=3),           # Pridan√©: posledn√© 3 hodiny
            '6h': timedelta(hours=6),
            '12h': timedelta(hours=12), 
            '24h': timedelta(hours=24),
            '7d': timedelta(days=7),
            '30d': timedelta(days=30),
            '90d': timedelta(days=90),
            '1y': timedelta(days=365)
        }
        
        if time_range not in time_mappings:
            return jsonify({'status': 'error', 'message': 'Neplatn√Ω ƒçasov√Ω rozsah'}), 400
            
        start_time = now - time_mappings[time_range]
        
        with get_db_connection() as conn:
            # Ping d√°ta s optimaliz√°ciou pre veƒæk√© datasety
            cursor = conn.cursor()
            
            # Pokroƒçil√Ω sampling pre extr√©mne veƒæk√© datasety (a≈æ 365 dn√≠ s 1s intervalmi)
            # PROBL√âM: rowid % sampling je neefekt√≠vny pre mili√≥ny z√°znamov
            # RIE≈†ENIE: ƒçasovo-based sampling + inteligentn√° hustota pre r√¥zne ƒçasti rozsahu
            
            # Najprv zist√≠me celkov√Ω poƒçet z√°znamov v rozsahu
            cursor.execute('''
                SELECT COUNT(*) FROM ping_history 
                WHERE device_id = ? AND timestamp >= ?
            ''', (device_id, start_time.isoformat()))
            total_count = cursor.fetchone()[0] or 0
            
            if time_range in ['30d', '90d', '1y']:
                # Pre najdlh≈°ie rozsahy: ƒçasovo-based sampling pre mas√≠vne datasety
                target_points = {'30d': 6000, '90d': 8000, '1y': 12000}[time_range]
                
                if total_count <= target_points:
                    # Ak je m√°lo d√°t, zoberie v≈°etko
                    cursor.execute('''
                        SELECT timestamp, avg_latency, packet_loss, status
                        FROM ping_history
                        WHERE device_id = ? AND timestamp >= ?
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat()))
                elif total_count > 100000:  # Pre mas√≠vne datasety (>100k z√°znamov)
                    # ƒåasovo-based sampling: rozdel rozsah na segmenty a zoberie vzorky z ka≈æd√©ho
                    days_in_range = {'30d': 30, '90d': 90, '1y': 365}[time_range]
                    samples_per_day = target_points // days_in_range
                    
                    # Stratifikovan√Ω sampling - vzorky z ka≈æd√©ho d≈àa
                    cursor.execute('''
                        WITH daily_samples AS (
                            SELECT timestamp, avg_latency, packet_loss, status,
                                   ROW_NUMBER() OVER (
                                       PARTITION BY DATE(timestamp) 
                                       ORDER BY timestamp
                                   ) as rn,
                                   COUNT(*) OVER (PARTITION BY DATE(timestamp)) as daily_count
                            FROM ping_history
                            WHERE device_id = ? AND timestamp >= ?
                        )
                        SELECT timestamp, avg_latency, packet_loss, status
                        FROM daily_samples
                        WHERE rn % MAX(1, daily_count / ?) = 0
                           OR timestamp >= datetime('now', '-24 hours')
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat(), samples_per_day))
                else:
                    # Stredne veƒæk√© datasety: adapt√≠vny rowid sampling
                    dynamic_interval = max(1, total_count // target_points)
                    cursor.execute('''
                        SELECT timestamp, avg_latency, packet_loss, status
                        FROM ping_history
                        WHERE device_id = ? AND timestamp >= ? 
                          AND (rowid % ? = 0 OR timestamp >= datetime('now', '-24 hours'))
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat(), dynamic_interval))
            elif time_range in ['24h', '7d']:
                # Pre stredn√© rozsahy: optimalizovan√© limity
                target_points = {'24h': 4000, '7d': 6000}[time_range]
                
                if total_count <= target_points:
                    cursor.execute('''
                        SELECT timestamp, avg_latency, packet_loss, status
                        FROM ping_history
                        WHERE device_id = ? AND timestamp >= ?
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat()))
                else:
                    dynamic_interval = max(1, total_count // target_points)
                    cursor.execute('''
                        SELECT timestamp, avg_latency, packet_loss, status
                        FROM ping_history
                        WHERE device_id = ? AND timestamp >= ? 
                          AND (rowid % ? = 0 OR timestamp >= datetime('now', '-2 hours'))
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat(), dynamic_interval))
            else:
                # Pre krat≈°ie rozsahy: v≈°etky d√°ta (ale s limitom pre bezpeƒçnos≈•)
                cursor.execute('''
                    SELECT timestamp, avg_latency, packet_loss, status
                    FROM ping_history
                    WHERE device_id = ? AND timestamp >= ?
                    ORDER BY timestamp ASC
                    LIMIT 50000
                ''', (device_id, start_time.isoformat()))
            
            ping_rows = cursor.fetchall()
            ping_data = []
            for row in ping_rows:
                ping_data.append({
                    'timestamp': row[0],
                    'avg_latency': row[1],
                    'packet_loss': row[2],
                    'status': row[3]
                })
            
            # SNMP d√°ta s rovnakou pokroƒçilou logikou
            cursor.execute('''
                SELECT COUNT(*) FROM snmp_history 
                WHERE device_id = ? AND timestamp >= ?
            ''', (device_id, start_time.isoformat()))
            total_snmp_count = cursor.fetchone()[0] or 0
            
            if time_range in ['30d', '90d', '1y']:
                target_points = {'30d': 6000, '90d': 8000, '1y': 12000}[time_range]
                
                if total_snmp_count <= target_points:
                    cursor.execute('''
                        SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                        FROM snmp_history
                        WHERE device_id = ? AND timestamp >= ?
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat()))
                elif total_snmp_count > 100000:  # Mas√≠vne SNMP datasety
                    days_in_range = {'30d': 30, '90d': 90, '1y': 365}[time_range]
                    samples_per_day = target_points // days_in_range
                    
                    cursor.execute('''
                        WITH daily_samples AS (
                            SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory,
                                   ROW_NUMBER() OVER (
                                       PARTITION BY DATE(timestamp) 
                                       ORDER BY timestamp
                                   ) as rn,
                                   COUNT(*) OVER (PARTITION BY DATE(timestamp)) as daily_count
                            FROM snmp_history
                            WHERE device_id = ? AND timestamp >= ?
                        )
                        SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                        FROM daily_samples
                        WHERE rn % MAX(1, daily_count / ?) = 0
                           OR timestamp >= datetime('now', '-24 hours')
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat(), samples_per_day))
                else:
                    dynamic_interval = max(1, total_snmp_count // target_points)
                    cursor.execute('''
                        SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                        FROM snmp_history
                        WHERE device_id = ? AND timestamp >= ? 
                          AND (rowid % ? = 0 OR timestamp >= datetime('now', '-24 hours'))
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat(), dynamic_interval))
            elif time_range in ['24h', '7d']:
                target_points = {'24h': 4000, '7d': 6000}[time_range]
                
                if total_snmp_count <= target_points:
                    cursor.execute('''
                        SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                        FROM snmp_history
                        WHERE device_id = ? AND timestamp >= ?
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat()))
                else:
                    dynamic_interval = max(1, total_snmp_count // target_points)
                    cursor.execute('''
                        SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                        FROM snmp_history
                        WHERE device_id = ? AND timestamp >= ? 
                          AND (rowid % ? = 0 OR timestamp >= datetime('now', '-2 hours'))
                        ORDER BY timestamp ASC
                    ''', (device_id, start_time.isoformat(), dynamic_interval))
            else:
                cursor.execute('''
                    SELECT timestamp, cpu_load, temperature, memory_usage, uptime, total_memory, free_memory
                    FROM snmp_history
                    WHERE device_id = ? AND timestamp >= ?
                    ORDER BY timestamp ASC
                    LIMIT 50000
                ''', (device_id, start_time.isoformat()))
            
            snmp_rows = cursor.fetchall()
            snmp_data = []
            for row in snmp_rows:
                if row[4] in (None, 'N/A'):
                    # Preskoƒç offline/pokazen√© SNMP z√°znamy, aby sa nevykresƒæovali ako akt√≠vne d√°ta
                    continue
                # Bezpeƒçn√© z√≠skanie memory hodn√¥t s type checking
                total_mem = row[5] if len(row) > 5 else None
                free_mem = row[6] if len(row) > 6 else None
                
                # Konverzia na int a valid√°cia
                try:
                    if total_mem is not None and str(total_mem).strip():
                        total_mem = int(total_mem)
                    else:
                        total_mem = None
                        
                    if free_mem is not None and str(free_mem).strip():
                        free_mem = int(free_mem)
                    else:
                        free_mem = None
                        
                    # V√Ωpoƒçet used_mem iba ak s√∫ oba platn√© ƒç√≠sla
                    used_mem = (total_mem - free_mem) if (total_mem is not None and free_mem is not None and total_mem >= 0 and free_mem >= 0) else None
                except (ValueError, TypeError) as e:
                    logger.warning(f"Memory data conversion error for device {device_id}: total_mem={repr(row[5])}, free_mem={repr(row[6])}, error: {e}")
                    total_mem = None
                    free_mem = None
                    used_mem = None
                
                snmp_data.append({
                    'timestamp': row[0],
                    'cpu_load': row[1],
                    'temperature': row[2], 
                    'memory_usage': row[3],
                    'uptime': row[4],
                    'total_memory': total_mem,  # MB
                    'free_memory': free_mem,    # MB
                    'used_memory': used_mem     # MB (vypoƒç√≠tan√©)
                })
                
        return jsonify({
            'status': 'success',
            'ping_data': ping_data,
            'snmp_data': snmp_data,
            'range': time_range,
            'start_time': start_time.isoformat(),
            'end_time': now.isoformat(),
            'ping_records': len(ping_data),
            'snmp_records': len(snmp_data),
            'optimized': time_range in ['24h', '7d', '30d', '90d', '1y']  # oznaƒçuje ƒçi sa pou≈æ√≠va ƒçasov√Ω sampling
        })
            
    except sqlite3.Error as e:
        logger.error(f"Datab√°zov√° chyba pri z√≠skavan√≠ monitoring hist√≥rie pre zariadenie {device_id}: {e}")
        return jsonify({'status': 'error', 'message': f'Chyba datab√°zy. Skontrolujte logy servera pre viac detailov. (Zariadenie ID: {device_id})'}), 500
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ monitoring hist√≥rie pre zariadenie {device_id}: {type(e).__name__}: {e}")
        import traceback
        logger.error(f"Stack trace: {traceback.format_exc()}")
        return jsonify({'status': 'error', 'message': f'Chyba servera. Skontrolujte logy servera pre viac detailov. (Zariadenie ID: {device_id})'}), 500

@app.route('/api/backup/status', methods=['GET'])
@login_required
def backup_status():
    """Vr√°ti stav v≈°etk√Ωch be≈æiacich z√°lohov"""
    running_backups = list(backup_tasks.keys())
    return jsonify({
        'running_backups': running_backups,
        'total_running': len(running_backups),
        'sequential_backup_running': sequential_backup_running,
        'sequential_backup_total': sequential_backup_total,
        'sequential_backup_current': sequential_backup_current
    })

@app.route('/api/backup/stop-all', methods=['POST'])
@login_required
def stop_all_backups():
    """Zastav√≠ v≈°etky be≈æiace z√°lohy"""
    global sequential_backup_running, sequential_backup_total, sequential_backup_current
    
    stopped_count = len(backup_tasks)
    stopped_ips = list(backup_tasks.keys())
    
    # Zastav√≠me sekvenƒçn√∫ z√°lohu ‚Äì aktu√°lne prebiehaj√∫ce √∫lohy nech√°me bezpeƒçne dobehn√∫≈•
    sequential_backup_running = False
    sequential_backup_total = 0
    sequential_backup_current = 0
    
    if stopped_count > 0:
        add_log('warning', f"Pou≈æ√≠vateƒæ po≈æiadal o zastavenie z√°loh ({stopped_count} zariaden√≠): {', '.join(stopped_ips)}")
        for ip in stopped_ips:
            socketio.emit('backup_status', {'ip': ip, 'status': 'stop_requested'})
        
        return jsonify({
            'status': 'success', 
            'message': 'Zastavenie z√°loh bolo po≈æadovan√©. Prebiehaj√∫ce √∫lohy sa dokonƒçia a nov√© sa nespustia.',
            'stopped_devices': stopped_ips
        })
    else:
        return jsonify({
            'status': 'info', 
            'message': '≈Ωiadne be≈æiace z√°lohy na zastavenie.'
        })

@app.route('/api/snmp/status', methods=['GET'])
def snmp_status():
    """Debug endpoint - zobraz√≠ SNMP stav v≈°etk√Ωch zariaden√≠"""
    try:
        with get_db_connection() as conn:
            settings = {row['key']: row['value'] for row in conn.execute('SELECT key, value FROM settings').fetchall()}
            global_interval = int(settings.get('snmp_check_interval_minutes', 10))
            
            devices = [dict(row) for row in conn.execute('SELECT id, ip, name, snmp_interval_minutes, last_snmp_check FROM devices ORDER BY name').fetchall()]
            current_time = datetime.now()
            
            status_info = []
            for device in devices:
                device_interval = device.get('snmp_interval_minutes', 0)
                effective_interval = device_interval if device_interval > 0 else global_interval
                
                last_check_info = "Nikdy"
                minutes_since_check = None
                next_check_info = "Hneƒè"
                
                if device.get('last_snmp_check'):
                    try:
                        last_check = datetime.fromisoformat(device['last_snmp_check'])
                        minutes_since_check = (current_time - last_check).total_seconds() / 60
                        last_check_info = f"{minutes_since_check:.1f} min dozadu"
                        
                        remaining_minutes = effective_interval - minutes_since_check
                        if remaining_minutes > 0:
                            next_check_info = f"Za {remaining_minutes:.1f} min"
                        else:
                            next_check_info = "Hneƒè"
                    except (ValueError, TypeError):
                        last_check_info = "Chyba parsingu"
                
                status_info.append({
                    'id': device['id'],
                    'name': device['name'],
                    'ip': device['ip'],
                    'interval_setting': device_interval,
                    'effective_interval': effective_interval,
                    'last_check': last_check_info,
                    'next_check': next_check_info,
                    'is_due': minutes_since_check is None or minutes_since_check >= effective_interval
                })
            
            return jsonify({
                'global_interval': global_interval,
                'devices': status_info,
                'current_time': current_time.isoformat()
            })
    except Exception as e:
        logger.error(f"Chyba pri z√≠skavan√≠ SNMP stavu: {e}")
        return jsonify({'error': str(e)}), 500

# Spustenie ping monitoringu po definovan√≠ v≈°etk√Ωch funkci√≠ (mimo app contextu)
start_ping_monitoring()

if __name__ == '__main__':
    try:
        # Nastavenie Flask produkƒçn√©ho prostredia
        os.environ['FLASK_ENV'] = 'production'
        app.config['ENV'] = 'production'
        
        logger.info("Sp√∫≈°≈•am MikroTik Manager...")
        
        # Inicializ√°cia datab√°zy
        init_database()
        
        # Spustenie ping monitoringu
        start_ping_monitoring()
        
        # Spustenie SNMP timerov pre v≈°etky zariadenia
        start_all_snmp_timers()
        
        logger.info("Aplik√°cia je pripraven√° na port 5000")
        # Spustenie aplik√°cie
        socketio.run(app, host='0.0.0.0', port=5000, debug=False)
        
    except KeyboardInterrupt:
        logger.info("Aplik√°cia ukonƒçen√° pou≈æ√≠vateƒæom")
    except Exception as e:
        logger.error(f"Kritick√° chyba: {e}")
        raise
